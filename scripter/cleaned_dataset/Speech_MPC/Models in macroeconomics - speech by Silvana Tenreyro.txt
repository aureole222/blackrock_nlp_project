 The views are not necessarily those of the Bank of England or the Monetary Policy Committee. I would like to thank Oliver Ashtari Tafti, Riccardo Masolo, Michael McLeay, Francesca Monti and Kate Reinold for their help producing this speech. I am also grateful to Thomas Belsham, Lizzie Drapper, Tomas Key, Chris Redl, Michael Saunders, Marco Schneebalg, Martin Seneca, Yad Selvakumar and Carlos Van Hombeeck for helpful comments. All errors are mine. ###newline###  Perhaps unsurprisingly, following a decade of slow economic recovery from a painful financial crisis, the role of economics and economists has been vociferously debated. A few weeks ago a newspaper article felt obliged to ask the question  Has economics failed? 1 Many critics have laid the blame on the tools that economists use   our models.2 3 So, in my speech today, I will attempt to shed some light on how and why economists use models. Specifically, I will focus on how they are useful to me as a practitioner on the MPC. I will also outline some of the current challenges we face in macroeconomic modelling. As I go through, I will illustrate how a wide range of economic models have been useful in informing my recent policy votes. On policy, I will emphasise three points. First, I expect that the tight labour market will continue to feed through into domestic cost pressures   I think that fears of a breakdown in the relationship between slack and inflation are misplaced. Second, although we have seen some unexpected weakness in the recent inflation and activity data, in my view, the most likely scenario is that the GDP news is short-lived, and we will need a limited and gradual tightening in Bank Rate over the next three years to keep demand growing in line with supply. Third, since the picture for underlying demand should become clearer relatively soon, I was comfortable leaving policy unchanged in our May meeting. Before discussing how economic models have contributed to shaping this policy view, it might be helpful to first explain what a model is! Models are essentially abstractions. They simplify what is actually going on by removing unnecessary details. An oft-used analogy is to think of models as maps.4 Maps simplify our complex world to small-scale, flat figures. When used for travelling, a map can show us the route we need to follow, abstracting from a host of information that is not essential to reach the destination. The map might be different (and more or less stylised) depending on the means of transportation (think of your favourite bicycle, foot, train, bus or car maps). In the same way, economic models might be different depending on the structure and characteristics of the economy; policy instruments available; institutional constraints; etc. For detailed arguments for and against many aspects of current macroeconomic modelling, see the 2018 special issue of Oxford Vlieghe (2017) discusses a related set of criticisms of forecasting and Shafik (2017a, 2017b) defends expert opinion in general. Many people have used the analogy before in different forms. One early example in the context of economics appears in While maps have become more accurate with improved data and technology, we are still surprised by unexpected delays, blocked roads or flooded paths. Similarly, economic models have improved with greater computing power, econometric techniques and data availability, but there is still significant uncertainty that cannot be eliminated. And of course, we need different maps for different purposes. Physical, topographic, climate, political or thematic maps all help simplify our complex world in different ways. Analogously, economists often resort to different models to think about different economic problems. ###newline###  The macroeconomic models currently used in central banks and in academia are a product of a long journey over the past century or so. It would be impossible in a short speech to cover even a small fraction of the many advances, twists, turns (and many dead ends) that have led us here. But to give some context to some of the current debates, I will try to summarise a few of the key developments.5 As with much in macroeconomics, the obvious place to start is with John Maynard Keynes, who published his General Theory in the depths of the Great Depression in 1936. With its focus on demand management, it arguably marked a clear break from earlier macroeconomic thought. It was also perhaps the single greatest influence on post-war macroeconomic policies. As a result, the early macroeconomic models that were built in support of those policies were resolutely  Keynesian  in nature. That legacy has continued to this day   much of the thinking underlying macroeconomic modelling today is still influenced by his insights. Despite its enduring impact, I expect that not many macroeconomic modellers will have spent too much time wading through Keynes s writing itself. Its influence has been more indirect. One reason why is that, rather than formal mathematical models as is common today, Keynes s arguments were advanced largely in prose. And while plain English can make ideas more accessible, it can also introduce ambiguity. Indeed, ever since, there have famously been debates in the profession over  what Keynes really meant .6 Moreover, the prose itself has been variously described as  complex ,  recondite , and  plodding .7 My colleague Andy Haldane has discussed how central bank publications perform badly on standard readability metrics.8 Keynes s General Theory is likely to score poorly too. Most students instead learn the interpretation of Keynes formalised in the simple (IS-LM) model of Hicks (1937). Some have argued that this interpretation is not the right one, or at least misses some of the nuance of the General Theory. But a major advantage of such formal mathematical models is that they can bring greater clarity and precision: while many have disagreed that the IS-LM model was the right one, economists share an understanding of what the model means. Indeed, in such a global discipline as economics, maths can also act as a lingua franca, reducing potential misunderstandings. From the simple IS-LM framework, models evolved to match the rapidly expanding macroeconomic data available. Around the same time, the first comprehensive sets of National Accounts were developed in the UK and the US. Coupled with various technical advances in econometrics, these encouraged the development of early macroeconomic models. For aggregate demand, these typically consisted of (IS) blocks explaining each of consumption and investment, with another (LM) block explaining the asset market; an empirical Phillips curve relationship determined how prices and wages responded to imbalances between demand and supply. The models grew in importance and commensurately in size.9 Large-scale macroeconomic models suffered a set of blows in the 1970s, which led to their falling rapidly out of favour in most modelling carried out in universities. One issue was a set of damaging methodological A second challenge came from the real-world development of stagflation   the 1970s occurrence of high inflation and unemployment. This was seen as evidence against existing models, which almost exclusively featured negative Phillips curve relationships between inflation and unemployment. The models were quickly adjusted to correct one cause of their breakdown   their failure to incorporate the effects of the large oil shocks of the 1970s. But events also supported the broader arguments of Lucas and others, who had expected that the Phillips curve would break down if policymakers attempted to exploit it by accommodating inflationary shocks, since rational workers would begin to anticipate that behaviour and raise their wage demands accordingly. Model design always involves a trade-off between realism   and so complexity   and tractability.10 The modeller must therefore make choices over which details are unnecessary   and from which one can By 1965, the Brookings econometric model had over 200 equations (including 75 identities) (Fromm and Klein, 1965). The Bank of England s quarterly model had nearly 300 equations in 1987 (Patterson et al, 1987). Over the past 25 years, there has been a gradual convergence between models used in policy institutions and in the academic literature. Building on the now dominant DSGE research methodology, ###newline###  Models help us to understand the potential effects of policies, to assess and quantify different mechanisms that might be at play and to consider interactions that might go beyond the direct or intended effects of the policy. I will expand on each of these points in turn. Good models help us clarify our intuition. When we want to know the effect of some action, we can often tell stories or conjecture mechanisms that might lead to different answers. A model can help us understand what might happen under different conditions and how different mechanisms might interact. An alternative option Patterson et al, (1987), Pagan (2003), Brayton and Mauskopf (1987) and Brayton et al (1997). might be to experiment. But this is not always possible when it comes to economics. That is doubly the case when it comes to working out the effect of macroeconomic policy. For macroeconomists, models are often the only way we can think through policy effects. And for an MPC member, that means monetary policy. We are tasked with setting Bank Rate to ensure that inflation reaches its 2% target. To work out how to do that, we need a good model of how Bank Rate affects the economy and inflation. We cannot just simply look at what happened to inflation when the MPC has increased Bank Rate before. For one thing, the MPC typically increases Bank Rate precisely when we expect inflation to rise above its target. So simply looking at the data will not disentangle the effect of the policy from the increase in inflation that was already expected to happen. Of course, clever econometricians   including many here at the University of Surrey   are able to find ways around to separate out confounding effects such as these. A massive amount of work has found ingenious ways to tease out  shocks  to monetary policy from the data.14 I have even made my own contribution to this collective research effort.15 But as policymakers, we are not in the business of trying to engineer such shocks. Most of my job involves trying to set policy to respond in a predictable and well-understood way to economic developments. To work out how the economy will respond to the effects of this systematic part of monetary policy, we need to use models.16 Moreover, the structure of the economy can change over time in ways that affect how policy works. Models allow us to think through how this might happen. Put differently, we often need models to try to work out the effects of impulses or interventions that we have not observed happen before. (Or have not happened enough times to allow us to reliably infer what might happen in future.) There will always be many models giving different answers. But we can try to judge which models are better by asking which ones are better able to explain the phenomena we have seen in the data.17 Often in macroeconomics there are many plausible stories as to why something has happened, or what might happen in future. We can use models to make sense of the data and give quantitative estimates of the Christiano, Eichenbaum and Evans (1996, 1999); Romer and Romer (2004); and, for the UK, Ellis, Mumtaz and Zabczyk (2013) and Cloyne and H rtgen (2016). size of different effects. To show how this can inform monetary policy, Chart 1 uses the Bank of England s COMPASS model to explain the behaviour of inflation over the past decade. The chart divides up the observed inflation data into the different  shocks  that are included in the model. Essentially it is the model s interpretation of the most likely drivers of inflation. For me, there are three main points that I take from this chart. First, I find the model s interpretation of why inflation has evolved as it has quite plausible, as long as we do not take it too literally. A key driver of the movements in inflation, according to the model, has been various cost-push shocks (purple bars).18 These caused above-target inflation in both 2008 and 2011-12, as well as below-target inflation in 2009 and 2015-16. These shocks often stand in for factors that affect prices over and above labour and capital costs, including changes in VAT and other costs not explicitly featured in the model, such as energy costs. And indeed, Chart 2 shows that the contribution of the purple bars to inflation is correlated with the peaks and troughs of oil-price inflation over the past decade or so. These cost-push shocks consist of a wage mark-up shock and several different price mark-up shocks. Oil price increases, which do not feature explicitly in the model, are likely to be identified as a combination of these shocks. This suggests one should be cautious in taking the model interpretation too literally. See Burgess et al (2013) for further discussion. The MPC s remit recognises that in the face of temporary shocks, attempting to keep inflation at target may cause undesirable volatility in output. Since the effects of oil-price swings are transitory, there is a good case for  looking through  their impact on inflation. Cost shocks aside, the next biggest drivers of inflation during the period were large negative shocks to demand (blue bars) in the years following the crisis, which were broadly offset by a rapid loosening in monetary policy (orange bars).19 And third, more recently, the exchange-rate has been pushing up on inflation since 2016. The model s interpretation of the data is consistent with that of the MPC: the fall in the pound after the EU referendum has been the main driver of recent above-target inflation. This pick-up and subsequent easing of imported inflation has been a feature of MPC forecasts ever since. But in the past few quarters, we have seen some building evidence that import prices have been rising slightly less than we had expected (only by around half of the increase in foreign export prices - Chart 3). For me, this may be one reason why CPI inflation has recently fallen back faster than we had expected. And on balance, I expect some of this downside news to persist. I therefore agreed with the MPC s collective judgement in May that, conditional on current market expectations for policy, the import-price contribution to CPI inflation is likely to be a little lower than in our February forecast (Chart 4). In principle, successful, systematic monetary policy might not appear at all in the model decomposition. The model contains a Taylor rule that describes how monetary policy responds to deviations of inflation from its target as well as to positive or negative output gaps. These systematic responses are already included in the demand (and other) shock bars in the decomposition   they would tend to make them smaller than otherwise. But in practice, even though the rule is estimated based on past behaviour, it is likely to be too simple to provide a good policy prescription following an event like the 2008 financial crisis. Interpreted via the rule, policy may appear to place more weight on the output gap (Weale, 2016) and less weight on interest-rate smoothing than on average over the sample. The macroeconomy is a highly interconnected system where many aggregate variables depend on each other. We often need models to help us make sense of what is happening in the data. Looking at simple correlations can be misleading when trying to work out complicated causal logic. To give a simple and topical example, with major implications for monetary policy, there has been much discussion recently over the elusiveness of the Phillips curve.20 The Phillips curve is an empirical model describing a negative relationship between rates of inflation and unemployment. Or, in modern versions, a positive relationship between inflation and the output gap (the difference between output and its potential). Incidentally, William Phillips, the economist who first identified the correlation between inflation and slack, was arguably the first economist to design an analogue computer (the MONIAC) to simulate the effect of macroeconomic policies.21 Many commentators have recently argued that the Phillips curve is no longer apparent in the data   the observed correlation between inflation and slack is much weaker than it has been in the past. If the Phillips curve truly has flattened or disappeared, then the current strength of the UK labour market may be less likely to translate into a pick-up in domestic inflationary pressures. Given that the Phillips curve is one of the building blocks of standard macroeconomic models, including those used by the MPC, a breakdown in the relationship would also call for a reassessment. Both in the UK and in other countries. See for example Giles (2017) and the discussion and references in Vlieghe (2018). See Forbes (2017) for more detail and a picture of one of the MONIAC machines. My view is that these fears are largely misplaced. I expect that the narrowing in labour market slack we have seen over the past year will lead to greater inflationary pressures, as in our standard models. To infer anything about the Phillips curve from the data, one needs to use a model that also takes into account the effect of monetary policy.22 The reason is that good monetary policy, by design, should aim to quickly close any gaps between output and its potential in order to achieve the inflation target. Even with a working Phillips curve, these actions will blur any positive correlation in the data. To illustrate why this is so, Charts 5a and 5b plot a Phillips curve relationship in blue, alongside a stylised description of monetary policy in red. The Phillips curve is a simple positive relationship between inflation and slack. When output increases relative to its potential (that is, a positive output gap opens), this causes above-target inflation. Conversely, a negative gap causes below-target inflation. But good monetary policy should seek to eliminate any such gaps and simultaneously stabilise inflation. The exception is when cost-push shocks create a trade-off between stabilising inflation and the output gap. In the face of large or persistent shocks that create a trade-off between these two goals, the MPC is required by our remit to strike a balance between the two   for example to reduce output below potential in the face of above-target inflation. The red line plots an example preferred trade-off, which will depend on the slope of Any time we see data on inflation and the output gap, we will be at the intersection of the red and blue lines. This means that we cannot interpret the observed data we see as the Phillips curve. If there are large cost-push shocks, such as changes in energy prices, then the Phillips curve will move around, as shown in the dashed blue lines in Chart 5a. A na ve econometrician running regressions of inflation on the output gap would see only the red circles and identify the negative monetary policy trade-off line, rather than the positive Phillips curve relationship. Successful monetary policy will make the Phillips curve harder to identify in the data. But in practice, policymakers cannot always perfectly offset fluctuations in demand. There will be unforeseen shocks that cause output and inflation to evolve differently to their forecasts. These will appear as if they are shifts in the preferred trade-off (Chart 5b). If these shifts are large relative to the cost-push shocks in Chart 5a, we may be able to observe the Phillips curve. But as policymakers, even though the Phillips curve underlies our models, we should always be doing our best to make it disappear in the data. This example highlights that it may not be possible to see the true relationships from looking at the data alone. We often need to use a model in such situations. Models can show us a broader picture and help us consider alternative mechanisms that may be driving the data. (Another option, for the econometricians in the room, is to come up with clever instruments, but they are not always available.) ###newline###  So far I have discussed some of the benefits of using macroeconomic models, as well some of the debates of the past that many economists thought had been settled. But compared to mapmaking, economic modelling is still a very imprecise science. And probably it will always be, as our economies and our understanding of them continue to evolve. (So too do our technical modelling capabilities.) As a result of all this, there will always be ample scope for improvement. I would like to pick out three areas where some of our standard models have been accused, with some justification, of being somewhat lacking: first, incorporating banks and the financial sector; second, realistically modelling people s expectations of the future; and third, taking into account the ways in which the distribution of different households and firms in the economy may matter.23 But I should also emphasise that I think there has been impressive progress on all three fronts. This list is also not exhaustive   I will briefly mention other areas where models could be improved. As in the 1970s, the biggest challenge to macroeconomic models has come from a real-world event: the 2008 financial crisis. Economists were charged with having ignored the financial sector in their models; Others have picked out similar sets of challenges, for example, Yellen (2016), as well as Vines and Wills (2018) in the overview article in the Oxford Review of Economic Policy special issue. some blamed policymakers for not acting against growing financial imbalances; and above all, economists were criticised for not predicting the crisis. While the charge that macroeconomic models failed to predict the financial crisis is fair, I think it helps to understand the reasons for that prediction failure. Models are used for forecasting, but it is by no means their only (or even their primary) role in macroeconomics. And most forecasting models are designed to predict the more frequent peaks and troughs we had seen in the economy in most of the post-war period, not rare events such as crises. Often the best we can do is to improve our understanding of crises that have happened in the past or in other countries and try to avoid the same phenomena happening again   and be prepared to react if they do happen. But even when we were able to identify worrying financial imbalances that might lead to crises, this would not mean that we would be able to predict their timing with any accuracy.24 I should emphasise that prior to the crisis, there were also large parts of the economics profession that did pay close attention to banks and the financial sector. There are entire literatures exploring bank runs and liquidity risk, moral hazard in banking, market microstructures and other important issues.25 With hindsight, it seems clear that macroeconomics should have included more of these insights into its models.26 This is exactly what has happened since the crisis, with a mountain of new papers that have added further insights to our understanding of real economy-financial sector interactions. It is easy to argue this after the fact, however. Models cannot include every aspect of reality, so the model-builder has to decide which features matter for a given question.27 I should add that even though many mainstream macroeconomic models did not feature a financial or banking sector before the crisis, the insights from the financial economics literature arguably played an important role in the response to the crisis, particularly in the form of liquidity provision through quantitative easing programs. Many macroeconomic models start from simplified   and, as such, unrealistic   assumptions over how households and businesses  behaviour depends on what will happen in the future. These features often lead to some unusual and implausible results. In particular, because expectations of the future are so important in the models, policies that work by affecting these can be incredibly powerful. This phenomenon has been dubbed the  forward guidance puzzle . (Here,  guidance  refers to promises And if policymakers successfully prevent crises, then we will never actually see many that would have otherwise occurred. For a tiny subsample, see Diamond and Dybvig (1983), Kyle (1985) and Dewatripont and Tirole (1995). There were of course exceptions, notably the financial accelerator model of Bernanke, Gertler and Gilchrist (1999). In fact, some policy models in the 1960s and 1970s had far more detailed financial sector modelling, which was simplified following about future monetary policy, rather than guidance of the type that the MPC has given, which has been intended to clarify our reaction function)28. Taken literally, the models suggest implausibly large economic effects from promises about interest rates many years in the future. There is ample empirical evidence that these strong assumptions do not hold in real-world data.29 Anecdotally, my visits to businesses around the country with the Bank s regional agents lead me to the same conclusion. When it comes to setting wages, for example, I have heard a number of times that companies focus on largely skill-specific salary benchmarks, which, in the model jargon, tend to be backward-looking. This contrasts with the assumption of forward-looking wage-setting behaviour in most models, and could explain some of the persistence we see in the real-world wage data. It is not yet clear how large a problem our assumptions on expectations are for many of our models. It seems obvious to me that assuming fully rational, perfectly informed households and businesses is rather extreme. But the other extreme   myopic, backward-looking expectations   would also be unrealistic. It was exactly that assumption that led our older models to perform so poorly in the 1970s, when inflation expectations rapidly increased in response to accommodative monetary policy. Encouragingly, lots of work is going into developing models that make more realistic assumptions. One set of research still assumes everyone is completely rational, but introduces limits to how easily people can collect and process information. Some models assume that people only update their information infrequently30 or imperfectly31. Others model the consequences of not knowing how others will behave, especially when that depends on what they expect you to do, which depends on what you expect them to do, and so on.32 A second strand of models takes its lead from psychology and looks at what happens when people do not always behave completely rationally. These behavioural models also have the potential to be more realistic: laboratory experiments consistently reveal systematic departures from rational behaviour.33 There is a wide range of approaches incorporating some of these insights into macroeconomic models. One much-followed is to suppose that although people do not know the entire true model of the economy, they are able to learn about it over time via econometric estimation.34 Others assume that people overweigh the more recent past when forming expectations about the future35, or that people dislike ambiguity   not being able to work out how likely something is to occur.36 Finally, some recent modelling assumes that given the complexity of the economy, people within it build a simplified model in which they pay more attention to some variables than others.37 Another unrealistic assumption in many macroeconomic models is that everyone is the same. Or more accurately, that everyone can be characterised by a single, representative household or firm. While unrealistic, this has helped ensure that the models remain simple enough to be able to solve (and understand), while still being based on microfounded individually optimal behaviour. As always, whether this simplification matters depends on the question we are using the model to address. If we are interested in the distributional effects of monetary policy, then so-called  representative agent  models will not be very useful.38 But while it is important to understand these effects, it is not the role of monetary policymakers to try to target particular segments of the population. The MPC remit is clear that we must target aggregate CPI inflation, while also taking into account other important macroeconomic variables such as growth and employment.39 (One could argue that flexible inflation targeting itself embeds distributional considerations, since high and volatile inflation and unemployment tend to affect the poorest in society the most.) Monetary policy should nonetheless pay close attention to distributions, since there is a multitude of ways in which these might affect aggregate outcomes. There is increasing empirical evidence supporting this observation.40 Studies suggest, for example, that following a change in monetary policy, there is a bigger change in spending by younger age groups and by households with low incomes or with mortgages. We therefore run the risk of being led astray if our models do not keep track of these distributions. Let me give a different example, also highly relevant for monetary policy. Although average weekly earnings (AWE) growth has now been strengthening since the middle of 2017, its persistent weakness had previously been a worry. Arithmetically, however, mean earnings growth will always be dominated by the wages of those at the top end of the distribution. It is less clear that this is the most relevant subset of workers for CPI inflation. When it comes to producing goods and services in the CPI basket, workers in the bottom half of the pay distribution may by disproportionately important. Their wage growth would then matter more for CPI inflation. Partly due to post-crisis increases in the minimum wage, pay for these workers has been growing at rates closer to its pre-crisis average (Chart 6). See Coibion et al (2012), Gornemann et al (2014), Best et al (2015), Cloyne, Ferreira and Surico (2016) and Wong (2016). We can also construct alternative summary statistics of the wage growth distribution. Chart 7 shows how the median of the distribution has evolved over time, similar to the Atlanta Fed wage growth measure often used in the US. Since the crisis, it has generally held up better than the AWE regular pay data. These distributional splits of the earnings data give me further confidence that the tight labour market will continue to feed through into domestic inflationary pressures. Over the past couple of decades economists have developed a range of models that do take distributions into account.41 Most recently, several authors have revisited the monetary policy transmission mechanism by introducing heterogeneous distributions of households, firms and workers into the common New Keynesian framework.42 A key result in these models is that monetary policy largely works through its indirect effects on income and employment, with only relatively small direct spending responses to changes in interest rates.43 There are of course several other areas where models could be improved. One area is international linkages, both through trade in goods and services, and through trade in financial assets. Another is solution methods. The early work of Bewley (1986), Huggett (1993) and Aiyagari (1994) focused on the study of the role of income and wealth distributions in the macroeconomy, while Den Haan (1997) and Krusell and Smith (1998) introduce heterogeneity into business cycle models. Kaplan, Moll and Violante (2017), Ravn and Sterk (2017) and Auclert (2017). See also Sterk and Tenreyro (2016). The Bank s COMPASS model also contains some differences between households, albeit to a more limited extent than some of the So far macroeconomists have often focused on simplified, linear versions of their models. With advances in computing power, it is now possible to explore important non-linear effects. I will leave a full discussion of these issues for another opportunity. As in the previous discussion of trade-offs in cartography, in all of these areas, economists will also need to weigh the gains from more realistic models against the cost of additional complexity and possible opacity. ###newline###  While aware of their limitations, I still find model-based analysis extremely useful on the MPC. There will always be some things missing from each of the models we use in economics, or some seemingly unrealistic assumptions. But I do not see this as a major problem, for a couple of reasons. First and foremost, is that the MPC s forecasts are judgement-based, rather than unthinkingly following some model output. One would not choose to follow a map if the terrain appeared different in reality: the dotted lines of a mountain footpath on an Ordnance Survey map could become a dangerous hazard following heavy snowfall. The same applies to our use of models. The model is best thought of as an advisor, used as an input into our decisions, rather than the author of our forecasts. And this has always been the case on the MPC. Second, even though we do use models to inform our projections, we do not focus exclusively on any one theoretical model. Different committee members will always place different weight on different models and data sources when coming to a policy decision. Speaking for myself, I value seeing results from several different types of models when analysing the data and constructing our forecasts. There are things missing from all models, so we are always likely to need to use a range of models to answer different questions. For example, since our main macroeconomic model, COMPASS, focuses on the behaviour of firms and households but does not explicitly model the financial sector, it is useful to look at results from alternative empirical models when assessing changes in credit market conditions.44 Or when forecasting the very near-term outlook, I would typically place more weight on statistical  nowcast  estimates than some of our more theory-driven models.45 A recent example of this point was our expectation for Q1 GDP, following the heavy snowfall in February and March. Ahead of the data release, our DSGE models would have had no way of anticipating that the snow might affect activity. But unlike the models, since we were aware of the possible impact, as we mentioned in our March minutes, we revised down our forecast of headline Q1 GDP growth to 0.3%, based on staff analysis using Google search data. As we now know, GDP growth came in even weaker than this at 0.1%. There are good reasons to think that some of this news was also snow-related: the output split of GDP showed relatively weak readings for sectors likely to be affected (construction and some parts of private non-distribution services   Chart 8). It is also likely that the Q1 figure will be revised up in later data vintages. Nonetheless, I do still take some signal from the weak outturn, especially when combined with some negative news elsewhere, such as a soft picture for the housing market. Unusually, we should get a much clearer picture of underlying growth momentum over a relatively short timeframe. ###newline###  I hope I have conveyed how and why macroeconomic models do have some use in interpreting the economic data. Let me now bring together some of the real-world examples to summarise my current view of the economic outlook. World GDP has been growing strongly for some time. But in the near-term, there have been some signs of a slight slowing in momentum. GDP came out weaker-than-expected in both the US and euro area in Q1, and there has been a modest but relatively broad-based softening in global PMI indicators. Overall, however, the data remain consistent with the robust global growth incorporated in the MPC s May IR forecast. We will need to remain watchful on this front, especially given recent increases in political uncertainty in Europe (and the associated market reaction), which is another factor that does not directly enter our models. The data flow on UK activity and inflation has also been slightly weaker than we expected in February. As I have discussed, I think that much of the downside Q1 GDP news is likely to be erratic, but it does increase the possibility of some underlying weakness in demand. The negative news on inflation, meanwhile, may partly relate to a lower contribution from imported inflation. It now looks likely that the effect of exchange-rate pass through on CPI inflation will fade slightly more quickly than we had expected. Set against that, the labour market has continued to tighten. I am unconvinced by reports of the death of the Phillips curve, so I expect this to translate into a pickup in domestic cost pressures. Indeed, annual private- sector regular pay growth reached 3% in March, while evidence from the distribution of wage growth also signals greater strength. With falling imported inflation offset by a gradual pick-up in domestic costs, I judge that conditional on the outlook I have just described, a gradual tightening in monetary policy will be necessary over the next three years to return inflation to target and keep demand growing broadly in line with supply. While I anticipate that a few rate rises will be needed, the timing of those rate rises is an open question. To show why, I will use some stylised optimal policy simulations, since model analysis of this sort is often a useful input into my policy view. Because the point I want to make relates to the future path of interest rates, I use a simplified, behavioural version of the COMPASS model, in which expectations have a less powerful role.46 ###newline###  The stylised optimal policy simulations are shown in Charts 9a and 9b. The black dashed lines show a baseline scenario where, conditional on an upward sloping path for Bank Rate, inflation is above target and expected to remain so for the following three years. For simplicity, the output gap (not shown) is closed throughout. The policymaker seeks to minimise deviations of inflation from target, with some weight on Specifically, this simplified version of COMPASS includes bounded rationality on the part of households, constructed using a similar approach to Gabaix (2014). output and interest rate volatility.47 The dark pink lines show the optimal policy in this scenario, which involves raising Bank Rate once immediately, then several more times over the following three years, successfully bringing inflation back to target by year two. The other lines instead show scenarios where the policymaker first decides to wait one quarter (green-blue line) or four quarters (orange line) before changing Bank Rate, after which they implement the new optimal policy. After waiting one quarter, the policymaker optimally raises Bank Rate slightly faster and further than they otherwise would have, but the inflation outcomes are almost identical. After waiting four quarters, the policymaker needs to raise Bank Rate somewhat more quickly, and ends up with inflation slightly above target until the middle of year three. The point I would like to emphasise from these simulations is that it may be possible to achieve very similar outcomes for inflation with somewhat different paths for Bank Rate.48 This is possible because to some extent, future changes in policy can act as substitutes for immediate changes.49 This is especially the case when the optimal path is relatively flat, since this means that it is easier for policy to achieve the same effect with a path of rate rises later that is still gradual. The flexibility is limited, however   waiting a few more quarters increases the likelihood that inflation overshoots the target. In May, I felt that as in these scenarios, the costs of waiting a short period of time for more information were small. And because unusually, we are likely to get a significantly clearer picture of the underlying strength of domestic demand quite soon, there were benefits to leaving policy unchanged. That information, filtered through some of our models, will be crucial in determining exactly when, in my view, the next rate rise should occur. ###newline###  I would like to finish by quoting Alfred Korzybski (1933).  A map is not the territory it represents, but, if correct, it has a similar structure to the territory, which accounts for its usefulness . I do not wish to overstretch the map analogy   economics will always be less accurate and less predictable than cartography. But we should keep working on our models because they do help our thinking   even though they will never predict everything in advance   we might know better how to respond to events once they occur. Optimal policy is computed by minimising, under commitment, a quadratic loss function including inflation deviations (with a weight of 1), the output gap (with weight of 0.15) and the change in the interest rate (weight of 2.5). Given the reduced role for expectations in the model, the distinction between optimal commitment and discretionary policies is smaller than would be the case in a model with fully rational expectations. This is despite the simulations being produced in a model that does not feature a powerful expectations channel.