 (1) All Bank of England. The views expressed in this paper are those of the authors, and not necessarily those of the Bank of England or its committees. We are grateful to Andrew Bell, Alex Brazier, Paul Brione, Marcus Buckmann, Oliver Bush, Patrick Calver, Shiv Chowla, Sebastian de-Ramon, Stephen Dickinson, Nic Garbarino, Andrew Gracie, Amit Kothiyal, Antoine Lallour, Katie Low, Damien Lynch, Clare Macallan, Alex Michie, Ali Moussavi, Casey Murphy, Tobi Neumann, Simon Pittaway, Amar Radia, Ani Rajan, Katie Rismanchi, Fiona Shaikh and Tamarah Shakir for comments and contributions. Philip Massoud and Karam Shergill provided excellent research assistance. ###newline###  The theme of this conference is  Rethinking Macroeconomic Policy . When it comes to financial stability, that theme could hardly be more appropriate. The global financial crisis has been the prompt for a complete rethink of financial stability and policies for achieving it. Over the course of the better part of a decade, a deep and wide-ranging international regulatory reform effort has been underway, as great as any since the Great Depression. On cost grounds alone, a systematic rethink and reform of regulatory standards has been fully justified. While the costs of the global financial crisis are still being counted, it seems likely they will be the largest since at least the Great Depression. Two approaches are typically used to gauge these costs of crisis: the cumulative loss of output relative to its trend and the cumulative fiscal costs of supporting the financial system.1 Let s take these in turn. In the US, the level of output is currently around 13% below a continuation of its pre-crisis trend. Ten years into the Great Depression, output was around 28% below its pre-crisis trend. Even if not quite on the scale of the 1930s, the global financial crisis has imposed a huge opportunity cost on US citizens. In the UK, the losses since the Great Recession, currently at around 16% of pre-crisis GDP, are larger than in the US and indeed larger than those that followed the Great Depression. The crisis opportunity costs for UK and Much the same picture emerges if we look at measures of the fiscal cost of crisis. Again, there are a number of methods for gauging this cost. But one simple metric is to look at the pattern of government debt-to-GDP ratios after the Great Depression and Great Recession, recognising that the larger part of the debt sustainability cost of crisis typically arises from the denominator shrinking than from the numerator rising. It suggests that, in the decade after the Great Depression, levels of government debt relative to GDP had increased by around 28 percentage points in the US, 9 percentage points in Germany, but actually declined in the UK. Since the Great Recession, levels of debt relative to GDP have increased by, on average, Figures in this paragraph calculate a continuation of pre-crisis GDP using the average growth rate of output in the 10 years preceding the crisis. 28 percentage points for the same set of countries. The fiscal cost of the Great Recession, at least on this metric, is larger than during the Great Depression. It is against this backdrop that policymakers internationally have engaged in a deep and wide rethink, rewrite and reform of the global regulatory rules of the game. Wide, reflecting the multi-faceted nature of the problems, market failures and market frictions exposed within the financial system during the crisis. Deep, reflecting the severity of the hit to balance sheets, risk appetite and economic activity that the crisis has inflicted and continues to inflict. The next section reviews these regulatory reform efforts and their impact on bank balance sheets and market metrics of banking risk. With a number of reforms yet to be fully enacted, it is too soon to be reaching definitive conclusions. Nonetheless, some of the key questions thrown up by these regulatory reforms - conceptual, empirical and practical - are now reasonably clear. We also have almost a decade s worth of additional evidence and research on which to draw when assessing these issues. The following sections discuss some of those issues, drawing on new research and evidence: the calibration of regulatory standards, balancing the costs and benefits of tighter regulation; the overall system of financial regulation, balancing underlaps and overlaps, simplicity and complexity, discretion and rules; the impact of reforms on incentives in the financial system, in particular incentives to avoid regulation; and the evolving role of macroprudential regulation in safeguarding stability of the financial system. The opportunities arise from the need to keep the regulatory framework fresh and agile. With the best will in the world, no one could say with certainty how the far-reaching and interwoven reforms to regulation over the past decade will precisely land. Judging how the financial system might adapt to future trends in financial technology is even harder to predict. As new evidence, incentives and innovation arise in the financial system, the opportunity is created for regulators to learn and adapt the regulatory framework Equally, there are also threats to financial stability from any process of change. History is replete with examples of regulatory standards being diluted or dismantled in the name of enhancing the dynamism of the financial system and the economy. To follow this course unthinkingly would risk repeating regulatory mistakes from the past, recent and distant. Only ten years on from the biggest crisis in several generations, there are already some eerie echoes of those siren voices. With that in mind, we conclude with some thoughts on issues which might be fruitful for future research on regulatory policy. ###newline###  There are already a number of detailed accounts of the regulatory reforms undertaken by international policymakers over the past decade (Carney (2017b), Duffie (2017), FSB (2017a), Greenwood et al (2017), Sarin and Summers (2017), Yellen (2017)). The following is a summarised and simplified account of the state of play. It partitions reform efforts into their microprudential and macroprudential components, recognising that the two often overlap and are usually mutually reinforcing in their impact. Under the umbrella of Basel III, international reform of microprudential regulation has focused on four key areas: capital, leverage, liquidity and resolution. Taking these in turn: These reforms to capital standards have, encouragingly, been implemented in full by nearly all countries internationally (FSB (2017a)). Comparing regulatory capital, pre- and post-reform, is not straightforward. But taking together changes in both the quantity and quality of capital, it has been estimated that Basel III raised risk-based capital standards for globally systemic banks by a factor of around ten (Cecchetti (2015)). One of the new elements of the Basel III package was to supplement risk-weighted capital standards with a risk-unweighted leverage ratio. Because this measure does not require banks or regulators to form a judgement on the riskiness of banks  assets, it is in principle simpler, more transparent and less subject to risk-weight arbitrage (Haldane and Madouros (2012)). Indeed, those were among the reasons a number of countries, including the US and Canada, had a leverage ratio regime ahead of the crisis.4 The Basel III leverage ratio, set at a minimum level of 3% Tier 1, is due to be implemented internationally by 2018. A second new element of the Basel III package was to augment solvency with liquidity-based standards. Banks  liquidity has long been a pre-occupation of the Basel Committee (Goodhart (2011)). But it took wholesale liquidity runs on the world s largest banks during the crisis to provide the impetus for internationally-agreed liquidity standards. Under Basel III, these take the form of a liquidity coverage ratio (LCR), designed to ensure banks have sufficient high-quality liquid assets to meet their 30-day liquidity needs; and a net stable funding ratio (NSFR), designed to ensure banks  funding profiles are sustainable. The LCR has been implemented in full in most countries; the NFSR is due for implementation by 2018.5 During the crisis, a crucial missing ingredient from the financial regulatory architecture was found to be the ability to wind up financial institutions in an orderly fashion   that is, while minimising disruption to financial markets and the economy and without exposing tax-payers to risk (FSB (2014)). A number of measures have been taken or are in progress to fill this gap, including the introduction of more effective national resolution regimes for financial firms and greater cross-border co-operation and co-ordination when dealing with international banks in situations of stress (FSB (2017c)). These new or augmented microprudential standards have been supplemented with a set of new macroprudential measures. These focus on safeguarding the stability of the financial system as a whole (Tucker (2009), Bank of England (2009, 2011)). The most significant of these reforms have focused on three areas: macroprudential capital buffers; stress-testing; and shadow banks. Historically, capital standards have been static requirements. As part of Basel III, a new time-varying component of banks  capital was added   the counter-cyclical capital buffer (CCyB). This recognises that And a number of countries, including the UK, introduced leverage ratio capital requirements in the aftermath of the crisis. risks to the financial system vary over the credit cycle, typically being highest at its peak and lowest at its trough. The CCyB aims to counteract somewhat that time-varying risk profile, with additional capital required during the upswing which can be released during the downswing. There is international reciprocity in the setting of the CCyB to reduce incentives for cross-border arbitrage (BCBS (2010a)). The framework has been implemented in most jurisdictions. Similarly, one of the key lessons of the crisis was that some institutions impose greater degrees of risk on the system because of their size, complexity or interconnectedness (FSB (2010)). Basel III recognises the need for these systemically-important firms to carry a structurally higher capital requirement, currently of up to 3.5%, to help mitigate the additional risk they bring to the system. These capital add-ons apply to the 30 designated global systemically-important banks (G-SIBs) and the roughly 160 domestic systemically- important banks (D-SIBs), to be phased-in between 2016 and 2019. Stress tests were used by regulators before the crisis to assess whether banks had sufficient capital to withstand an adverse tail event. But these tests tended to be neither comprehensive nor transparent. In 2009, the US authorities undertook a comprehensive stress test of the major US banks and published the results. For banks failing the test, regulatory restrictions on their behaviour were imposed. For some people, this marked the turning point for the US financial system. A comprehensive annual stress-testing exercise is now undertaken in the US.6 More recently, the US has been joined by the UK and the EU, among others.7 Supporting this package of regulatory reforms, micro- and macroprudential, have been initiatives to boost the quantity and quality of reporting by financial institutions. These should help in pricing institution-specific risk by financial markets and ratings agencies. Notable initiatives have included:  enhanced Pillar 3 disclosures by banks, covering all aspects of the regulatory reform agenda; and the work of the Enhanced Disclosure Task Force (EDTF), a private sector group established by the FSB. Over time, this has led to increased compliance with the EDTF disclosure template (Chart 3). So what has been the impact of these regulatory reform measures on banks  overall resilience? One simple set of resilience metrics focusses on bank balance sheet measures of solvency and liquidity. Comparisons of international banks  balance sheets are made difficult by changes over time in both the definitions of variables and the sample of banks. We consider a panel of international banks, designated as either global systemically-important (G-SIB) by the FSB in 2016, or domestic systemically-important (D-SIB). This gives a panel of 30 G-SIBs and about 160 D-SIBs.8 For each bank, we consider two solvency-based metrics (leverage and risk-weighted capital) and two liquidity-based metrics (a simple liquid asset ratio and the ratio of loans to deposits). These measures do not map precisely to Basel definitions.9 Chart 4 looks at a measure of banks  Tier 1 risk-weighted capital ratios. For both G-SIBs and D-SIBs in our sample, these have risen significantly over the past decade, almost doubling from around 7-8% to around 13-14%. A very similar picture emerges for leverage ratios (Chart 5). These have also roughly doubled over the past decade, from around 3% to around 6%. On these metrics, there has been a material strengthening in solvency-based standards among systemically-important banks over the past decade. This is also the case for measures of TLAC (see Chart 6 for a sample of UK banks). Liquidity metrics show a similar pattern of improvement. For example, liquid asset ratios - high-quality liquid assets as a fraction of the total balance sheet   have risen from around 6% in 2008 to more than 8% (Chart 7), though the increase is more muted for D-SIBs. Meanwhile, the ratio of loans to deposits (LTD) has also improved, with lending backed by a larger share of stable sources of funding than before the crisis (Chart 8). A second set of metrics of bank solvency and liquidity focus on financial market perceptions of bank risk. There are a wide variety of potential such metrics, each with their own imperfections, including measures of default such as CDS spreads, bond yields and ratings; measures of volatility, such as option-implied volatilities; and measures of profitability, such as price-earnings ratios. These are summarised and evaluated in Sarin and Summers (2016). US bank holding companies (BHCs) subject to the Federal Reserve s annual Comprehensive Capital Analysis and Review (CCAR) as of March 2014. Chart 9 plots a measure of default   CDS spreads   for a panel of G-SIBs. It shows a familiar pattern of pre-crisis under-pricing of risk; a rapid re-pricing of default risk during the crisis; and a subsequent partial unwind. CDS spreads today sit roughly midway between their pre-crisis and mid-crisis averages. Bank bond spreads and ratings tell a similar story. Assuming pre-crisis banking risk was materially under-priced, this evidence is consistent with regulatory reform having boosted the resilience of the global banking system. At the same time, measures of bank volatility and profitability have seen fewer signs of recovery. Chart 10 plots a measure of the price-to-book ratio of G-SIBs and D-SIBs. This currently lies well below its historic average and little different than unity. Put differently, if we used a measure of banks  capital ratios using the market rather than the book value of their equity, this would suggest a far smaller degree of improvement in measured bank solvency and resilience (Chart 11), though the effect is less pronounced for D-SIBs. Sarin and Summers (2016) reconcile these market movements by appealing to the shifts in the franchise value of banks. Improved solvency standards have decreased the perceived default risk of banks. But coincident with lower risk are lower returns to banks  activities, due to the combined effects of stricter regulation, misconduct fines, low levels of interest rates and increased competition. This leaves banks a riskier proposition for equity investors than before the crisis, as the residual claimant on profits. But, by and large, improved solvency standards have reduced risk among bond-holders and depositors in banks. ###newline###  Is the calibration of these new regulatory standards too tough, too lax or just right?  That has been among the most animated of the regulatory debates over the past decade. One standard for comparison is historical experience.  There has been a significant evolution in the levels of both capital and liquidity ratios of the major banks over the past century.  Chart 13 plots a measure of the leverage ratio for the UK and US banking systems over a long historical sweep,10 while Chart 14 plots a simple measure of the liquidity ratio for UK banks over the past half-century (see also Jord  et al (2017)). Both solvency and liquidity ratios have exhibited a long, downwards drift. Between the end of the Chart 13 is not directly comparable with Chart 5 because it is based on a different definition of leverage and sample of banks. 19th century and the troughs prior to the financial crisis, leverage ratios fell by around three quarters in the US and the UK. Liquid asset ratios among UK banks underwent an even larger fall in less than half the time. Given the scale of these falls, even with the regulatory reforms of the past decade, levels of capital and liquidity in the banking system are at levels significantly below those 100 and 50 years ago, respectively. On the face of it, this gives grounds for questioning whether even these revamped regulatory standards are sufficient to withstand likely future shocks. We should, however, probably be cautious about jumping too quickly to that conclusion. Over the past century, there has been significant change in the structure of the financial system, including in the structure, scale and scope of financial regulation and the safety net. Those changes could mean that simple, historical comparisons of regulatory standards are misleading. Admati and Hellwig (2013) provide a comprehensive and lucid account of the case for higher capital standards. Their argument centres on the fact that the impact of higher capital standards on banks  overall cost of capital needs to take account of the lower risk that arises from this shift - the Modigliani-Miller offset (Modigliani and Miller (1958)). It needs also to distinguish between any private costs to banks from tighter regulation and the social benefits this confers, with the latter the key public policy yardstick. When it came to re-calibrating regulatory standards for capital and liquidity after the crisis, international regulators engaged in a detailed, quantitative exercise which sought to weigh these social costs and benefits of tighter regulation, drawing on existing empirical evidence. The Long-Term Economic Impact (LEI) study, published by the Basel Committee in 2010, is a useful starting point for discussion of the appropriate calibration of regulatory standards (BCBS (2010b)). The main conclusion from this work was that, under conservative assumptions about likely economic costs, there were positive economic benefits to society from a sizeable increase in the capital banks were required to maintain. The study did not settle on an optimal level of bank capital. But the results presented were consistent with societal benefits peaking at a Tier 1 risk-weighted capital ratio of between 16-19%.11 This is north of most global banks  current capital ratios. The range of published estimates in the LEI study reflected different assumptions about the persistence of the effects of crises on GDP, an area of particular empirical uncertainty in the academic literature. A contemporaneous study by Miles et al (2013) concluded that optimal capital requirements were likely to be higher   perhaps around 20% - if account was taken of the offsetting risk and cost of capital effects of higher solvency standards (the Modigliani-Miller offset). It is useful to revisit the calibration in the LEI study in the light of subsequent research. A little notation may be useful to organise this evidence. Suppose the aim of policy is to keep output in the economy, y, as close These figures are expressed in terms of current definitions of capital and risk-weighted assets. The mapping from the estimates reported in the LEI report and those above are due to Brooke et al (2015). as possible to its trend growth path, y .  The objective for the authorities is then to minimise a loss function, which can be written as: Let s simplify further and assume two factors can cause output to deviate from its trend: first, higher capital requirements, k, which act to reduce output each period by  ; and second, the occurrence of a financial crisis which, with probability  , leads to a discrete drop in output of  . That is: This captures the view that higher bank capital could reduce credit supply, and hence economic activity, in the near term. But by making the financial system more resilient to future shocks, it may also reduce the tail risk of bad macroeconomic outcomes. Both probability and severity of crises are influenced negatively by the level of bank capital, with the relationship likely to be convex ( (k) < 0,  (k) > 0,  (k)  <  0,  (k)  > 0)   that is to say, one would expect a one percentage point increase in the capital ratio to have a larger dampening impact on the probability and severity of crisis when banks are close to their regulatory minima than when capital buffers are plentiful. Optimal capital is higher the lower is  , the economic cost of a marginal increase in capital requirements; the greater are   and  , the likelihood and severity of crises; and the greater are   and  , the marginal effects of capital on the likelihood and severity of crises. So what have we learned over the past decade about the likely magnitude of these parameters? The assumptions underpinning the marginal benefits of higher capital in the LEI study were as follows: banking crises occur, on average, once every 20-25 years; the median estimate of the cumulative discounted costs of a crisis is around 60% of annual pre-crisis GDP; each percentage point increase in the capital ratio reduces the probability of a banking crisis by a smaller amount, ranging from 1.4% to 1% (for a capital increase from 10% to 11%) to 0.4% to 0.3% (for a capital increase from 14% to 15%); and, finally, the level of bank capital has no impact on the severity of crisis. Since the LEI report, a rich seam of the literature has emerged on the determinants of crises and their severity ( ). Some of the most illuminating pieces of this research have drawn on evidence from a long historical time-series and across multiple countries (for example, Jord  et al (2013), Taylor (2015)). The key findings are as follows. First, credit booms are probably the single most important determinant both of the likelihood of crises and of economic performance in the recovery after them (Schularick and Taylor (2012), Jord  et al (2013)). A sustained 1 percentage point increase in the credit-to-GDP ratio raises the probability of crisis from 4% to around 4.3% per year. It also raises the severity of a crisis, with real GDP per capita almost 1% lower after five years.12 Colleagues at the Bank of England have considered whether it is the level of credit, or its growth, prior to a crisis that matters most for subsequent economic performance (Bridges et al (2017)). They find that credit growth has historically been a significant predictor of crisis severity, whereas the level of indebtedness appears less important. Taken together, this evidence is consistent with the probability ( ) and output costs of credit crises ( ) being at least as large as assumed in the original LEI study, perhaps larger, given the still-high levels of the credit-to-GDP ratio in most countries, and the monetary and fiscal space available to the authorities at present relative to the average of the past   a recent paper by Romer and Romer (2017) presents evidence that this factor is a significant determinant of crisis severity. The still-accumulating output losses during the recovery phase from this time s crisis would also point in this direction (Chart 1). What role does higher bank capital play in reducing the likelihood of financial crises ( ) or their severity ( )? At least for the likelihood of crisis, subsequent evidence has tended to be rather ambiguous. Historical evidence, using aggregate economy-wide covariates, has reached the perhaps surprising conclusion that bank capital ratios have virtually no predictive power for the occurrence of financial crises in major advanced economies (Jord  et al (2017)). That is,   is indistinguishable from zero. This result holds both in the full Micro-econometric studies on the link between bank failure and bank capital have found a more tangible relationship, however. For example, Vazquez and Federico (2015) find that US and EU banks with stronger This echoes and extends findings from earlier research by Borio and Lowe (2002), Borio and Lowe (2004) and Drehmann, Borio and Tsatsaronis (2011), which found credit gap measures to be key determinants of crisis risk. pre-crisis capital and structural liquidity positions were less likely to fail. Berger and Bouwman (2013) report a similar finding using a longer-run data set of US banks. And a recent study by IMF economists finds that risk-based capital ratios in the range 15-23% would have been sufficient to absorb losses in the vast majority of past advanced economy banking crises (Dagher et al (2016)).13 At the time of the Basel Committee s study, there was little evidence on the impact of bank capital on the severity of crises ( ), which is why this channel was ignored in the quantitative calibration. That has since changed. Jord  et al (2017) find that, while bank capital does not prevent a crisis from occurring, it matters for the pain suffered in its aftermath. They find that real GDP per head is 5 per cent higher 5 years after the onset of a crisis-related recession if bank capital is above its historical average when the crisis hits. The benefits of capital in reducing the severity of crisis are also borne out by experience since the crisis. Chart 15 plots international banks  capital ratios prior to the crisis against their subsequent lending growth. The relationship has a statistically significant upward slope. Banks that entered the crisis with higher capital have, on average, been better able to continue their lending. On average, each extra 1 percentage point of pre-crisis capital boosted banks  cumulative lending over the subsequent decade by over 20%. This finding is corroborated by micro-econometric evidence. Carlson et al (2013) find that US banks with higher pre-crisis capital ratios had stronger loan growth in its aftermath, with the effect particularly pronounced at lower capital ratios. Cornett et al (2011) and Kapan and Minoiu (2013) report that banks relying more heavily on stable sources of funding, such as core deposits and equity capital, continued to lend relative to other banks during the crisis. And Jimenez et al (2014) find that, in periods of economic weakness, loan applications were less likely to be rejected by Spanish banks that were well-capitalised. A recent paper by Bank of England colleagues identifies a distinct channel through which bank capital affects crisis severity (Tracey, Schnittker and Sowerbutts (2017)). They use banks  misconduct fines as a novel instrument to identify exogenous negative bank capital shocks. They find that banks respond to such shocks by relaxing their lending standards, as measured by the loan-to-value and loan-to-income ratios on new mortgages. This is likely to increase their vulnerability to future shocks, increasing crisis severity. This evidence suggests that some of the benefits of higher capital requirements may have been understated in the original LEI study, with implications for the range of optimal capital requirements. For example, if we assumed that every percentage point of extra capital increased the level of real GDP each period in the Relatedly, Demirguc-Kunt et al (2010) and Beltratti and Stulz (2012) find that poorly capitalised banks had lower stock returns during the financial crisis. And Boyson et al (2014) find that banks that entered the recent financial crisis with higher capital were less likely to see their funding dry up during the crisis. aftermath of a crisis by 0.1%   broadly consistent with the evidence here - this would raise optimal capital requirement by around 2 percentage points, other things equal.14 Working in the opposite direction, however, have been developments in resolution arrangements and new standards for TLAC. No account was taken of these in the LEI study. But if TLAC can be credibly bailed-in, including for systemically-important institutions, this would tend to reduce both the likelihood and severity of future crises.15 It may also discipline banks  management, avoiding them taking excessive risks in the first place. Some studies suggest this market discipline effect could be material, reducing the likelihood of a financial crisis by as much as 30% (Afonso et al (2015), Brandao-Marques et al (2013)). Colleagues at the Bank of England (Brooke et al (2015)) have estimated that, if these measures of the beneficial incentive effects of TLAC and credible resolution regimes are correct, and if increased resolvability in addition reduces the cost of crises by around 60%,16 then optimal capital ratios for the UK banking system could be up to 5 percentage points lower than would otherwise be the case. A recent study by economists at the Federal Reserve Board (Firestone et al (2017)) also considers the impact of improved resolution arrangements. They use estimates from Homar and van Wijnbergen (2016) to model a reduction in the expected duration of crises from such arrangements. Overall, they find that optimal capital levels for the US banking system can range from 13% to 25%. The costs of higher bank capital requirements arise from potentially tighter credit supply conditions. Banks may adjust to the need to fund themselves with more equity by tightening lending rates and restricting loan volumes. The LEI study assumed that each percentage point increase in the capital ratio would raise loan spreads by around 13 basis points. That translated into a fall in GDP of around 0.1% relative to trend.17 What have we learned about these costs since the LEI study? Cecchetti (2014) documents how banks have adjusted their balance sheets and credit provision since the introduction of Basel III. He finds that banks increased their capital ratios significantly, by over 4 percentage points on average, across his sample. Net interest margins and profitability fell. But with the exception of European banks, banks  assets increased, their lending spreads narrowed, lending standards eased, and the ratio of bank credit-to-GDP went up. This calculation is based on the marginal condition for optimal capital reported earlier. We parameterise the crisis probability and severity functions as follows:   = exp( 0 +  1 ) (1 + exp( 0 +  1 ));  =  0 +  1 . The model is calibrated to deliver an optimal capital ratio of around 18% when  1 = 0, i.e. the LEI case. We achieve this by setting   = 0.1,  0 = 0.5,  1 =  0.2, and  0 = 10, that is to say, a crisis reduces the level of GDP by 10% relative to baseline. If instead we set  1 =  0.1, such that each percentage point increase in capital reduced the GDP hit in a crisis by 0.1%, the optimal capital ratio increases to over 20%. This estimate is based on the difference in the estimated cost of crises across their sample depending on whether they occurred under more or less credible resolution regimes. Admati and Hellwig (2013) have forcefully questioned the basis for assuming such costs, given that standard finance theory would A recent paper from the BIS (Gambacorta and Shin (2016)) reaches a similar conclusion. It finds that banks with higher unweighted capital ratios have tended to have higher loan growth, with each one percentage point increase being associated with higher subsequent lending growth of 0.6 percentage points per year. This evidence is consistent with the macroeconomic costs of higher bank capital being lower than assumed in the Basel LEI study. Indeed, taken at face value, it would suggest there have been virtually no costs of achieving higher levels of capital across the global banking system, at least among most global banks. While credit conditions have clearly improved since the crisis, it is possible that the recovery in lending might have been stronger still had capital requirements risen by less. To begin to analyse that question, Chart 16 compares the change in bank capital since Basel III was introduced with subsequent lending growth among a panel of large international banks. On average, lending growth has been positive over this period, consistent with Cecchetti (2014). But credit growth has also tended to be statistically significantly lower among banks that have seen the largest increase in their capital ratios. On average, banks that have increased their capital ratios by an extra one percentage point have provided 4% less in cumulative credit since Basel III was introduced (3.5% less if we exclude European banks). This is very similar to the estimates used by the FSB s Macroeconomic Assessment Group (2010), which reported a range of estimates from -0.7% to -3.6%. There are of course different possible interpretations of this negative relationship. Banks facing weak macroeconomic conditions may simply have seen a reduction in loan demand and responded by maintaining higher capital buffers on a voluntary basis. To parse these conflicting interpretations, we turn to recent econometric evidence on the impact of higher capital requirements. Aiyar et al (2014, 2016) find that shifts in required capital had large negative effects on UK banks  lending decisions. De-Ramon et al (2016) report a similar finding, noting that this has, if anything, increased since the crisis. Bahaj et al (2016) find that, in times of credit expansion, higher required capital has only a minimal effect on lending. But when credit growth is weak, higher required capital can result in a large reduction in lending. This echoes previous research which has found that banks reduce lending in response to negative capital shocks (Peek and Rosengren (1995)). Lower lending was one cost of higher equity considered in the LEI study. A second potential cost, not considered by the LEI study, was the potential for falls in market liquidity in core financial markets - for example, securities financing markets such as repo. This could potentially raise the cost of capital for users of these markets. Market commentary in recent years has often laid the blame at the leverage ratio. This, it is argued, has led some dealer-banks to reduce their inventory holdings and market-making capacity, thereby reducing secondary market liquidity in some markets. There are of course a variety of other reasons why banks  willingness to make markets, and why market liquidity more generally, might have been affected by the crisis   for example, reduced risk appetite and increased counterparty risk. Moreover, it was plausibly the case that pre-crisis liquidity may have been too plentiful and too cheap in some financial markets, so some correction in the quantity and pricing of liquidity was to be expected, and indeed was potentially desirable, from a welfare perspective. Research at the Bank of England has sought to identify the impact of leverage ratio requirements on the functioning of UK government bond ( gilt ) and gilt repo markets, using transaction-level data (Bicu et al (forthcoming)).18 It does find some causal impact of the leverage requirement on various metrics of liquidity, a worsening that is particularly acute at quarter-ends. Significantly, the banks most constrained by the leverage ratio reduced their activity in financial markets most. At the same time, however, dealers unaffected by the leverage ratio requirement also reduced their liquidity provision and, if anything, by more. This suggests factors other than the leverage ratio may have been at work in curtailing liquidity in these markets. It also leaves open the question of whether the correction in liquidity, even if privately costly, came at any social cost. Baranova, Liu and Shakir (2017) assess the costs that could arise from regulation which affects market liquidity at different levels of stress. They find higher costs in benign conditions, but substantial benefits in situations of stress as dealers make markets for longer. How do these research findings tilt the optimal bank capital calculus relative to the LEI study? Table 1 summarises the evidence. They are a mixed bag. On the benefits side, there is now stronger evidence on the costs of credit booms and the role of capital in constraining the severity of the downturn in the aftermath of these booms.  It also suggests that the costs of raising extra capital are no larger, and may well be smaller, than originally anticipated. This strengthens the hand of macroprudential authorities when tightening capital requirements during a credit boom. Other things equal, it would also increase quantitative estimates of banks  optimal capital ratio. On the other side of the ledger, the LEI study did not anticipate two factors. First, the role of TLAC in augmenting banks  capital base in situations of stress, potentially reducing the probability and severity of crises. Second, higher capital requirements could impose liquidity-related costs on the financial system, though their scale (and whether they are a social cost) remains open for debate. These arguments, in particular around resolution, have been used by policymakers in some countries, including the UK, when coming the view that capital requirements should be lower than in the original LEI study. For example, having assessed all the factors and evidence within Table 1, the Bank of England s Financial Policy Committee judged that the appropriate structural level of Tier 1 equity in the system would be 13  % of See the Financial Policy Committee s June 2016 Financial Stability Report (pp 27-33) for an assessment of market liquidity in UK markets more broadly. The Securities and Exchange Commission s Report to Congress contains a detailed assessment of the impact of Basel III and the Volcker Rule on liquidity in US Treasury and corporate debt markets (SEC (2017)). ###newline###  Regulatory reform has tended to progress crisis by crisis, market failure by market failure, regulatory standard by regulatory standard. This is not especially surprising, given the nature of the policy design process. Nonetheless, if we put together the various pieces of recent regulatory reform, we find a fundamentally different regulatory jigsaw, or system of financial regulation, than in the past. One important dimension of that new architecture is the significantly larger number of regulatory rules or constraints that now operate. On top of risk-based capital standards have been added regulatory rules for liquidity, leverage and loss-absorbing capital. In other words, we have moved from a system of largely uni-polar regulation to multi-polar regulation (Haldane (2015)). Some individual parts of the regulatory rulebook - such as the use of internal ratings-based risk weights - also remain complex. The new regulatory architecture has also introduced measures which are likely to make for a greater degree of regulatory discretion. The authorities in the US, UK and euro area have moved to annual stress-testing exercises in which the stress scenario, modelling framework, success criteria and regulatory response are each subject to significant degrees of regulatory discretion. Regulators internationally are also now setting a CCyB requirement, which is also set in a largely discretionary fashion. In short, the new regulatory framework involves a larger number of regulatory constraints, many of which are individually complex, operating with a greater degree of regulatory discretion than in the past. Some have questioned whether this system may be too complex (for example, Admati and Hellwig (2011)). And some of the recent debate on regulatory reform in the US also raises those same concerns (US Department of the Treasury (2017)). There are several different dimensions to regulatory complexity. Much has already been written on the complexity of individual rules or regulatory constraints and the associated potential for regulatory arbitrage (Haldane and Madouros (2012), Aikman et al (2014), Behn, Haselmann, and Vig (2016)). The Basel Committee s Task Force on Simplicity and Transparency are looking into these questions at a practical level. We do not explore those issues further here. Instead, we focus on two other dimensions of the system of financial regulation: (i) the number of regulatory constraints; and (ii) the extent of discretion around each individual regulatory rule. ###newline###  Although the post-crisis architecture places many regulatory constraints on banks, the key going-concern constraints are risk-weighted capital requirements (RWCR), the leverage ratio (LR), the liquidity coverage ratio (LCR) and the net stable funding ratio (NSFR). We assess these four constraints, recognising that other aspects of the regulatory system might also impose binding constraints on banks. For example, stress testing can be interpreted as holding banks to a different RWCR standard and a potentially different overall capital calibration (Greenwood et al (2017)). over-identified, with potentially distortionary implications for banks  business models and behaviour. For example, Greenwood et al (2017) argue that it may be distortionary and unnecessary to have multiple, independent constraints on banks  behaviour. And Cecchetti and Kashyap (2016) suggest that the LCR and NSFR are strongly overlapping in their impact, so that both may not be needed. These are well-reasoned critiques of the new regulatory framework whose messages should be analysed carefully when evaluating the new framework. They are just the sort of academic challenge to regulatory orthodoxy which was so missing in the pre-crisis period. Nonetheless, it is also worth reminding ourselves why and how such a multiple-constraint framework was arrived at in the first place. At a conceptual level, three arguments could be used to justify such a multi-pronged approach. First, banks are subject to multiple sources of risk or balance sheet fault-line. Historical experience suggests they fail for a variety of different reasons. To misquote Tolstoy, while sound banks tend all to be alike, unsound banks tend to be unsound in their own way. At least in principle, this could point to the need for different types of regulatory constraint to counter different balance sheet fault-lines: one instrument for each market failure. This is, if you like, the Tinbergen Rule as it applies to financial regulation (Tinbergen (1952)). Second, uncertainty as well as risk is pervasive in the financial system. These Knightian (1921) uncertainties have multiple sources - measurement of the risks banks face, how contagion propagates across the financial system and how regulatory actions affects behaviour, to name but three. A portfolio of regulatory tools can be seen as a means of offering insurance against these uncertainties. This is, if you like, the Brainard Rule as it applies to financial regulation (Brainard (1967)). Third, any individual regulatory constraint creates incentives for banks to respond in ways which may seek to avoid or arbitrage the rules. In the next section, we discuss how having multiple regulatory constraints might mitigate this risk. In this section, we discuss the conceptual case for multiple regulatory constraints before presenting some new empirical evidence. Table 2 summarises some of the key arguments. ###newline###  The last part of this sentence is, however, an important proviso. One key question is whether risks in the financial system are likely to be known with sufficient certainty that they can be estimated meaningfully and accurately. Based on historical experience, that assumption cannot be taken for granted when it comes to estimating financial risks. As discussed by Aikman et al (2014), there are at least three reasons for this. First, assigning probabilities is particularly difficult with rare, high-impact events, such as financial crises or the failure of a large financial institution. Degrees of freedom are small in number, historical precedents rarely exact and causal mechanisms imperfectly understood. This means estimated default probabilities, and losses given default, are often highly imprecise. Indeed, that is (one reason) why model-based estimates of the same underlying risks can differ so significantly across banks (BCBS (2014a)). Second, the behaviour of complex, interconnected financial systems can be very sensitive to small changes in initial conditions and shocks. That might be because these systems exhibit multiple equilibria, with path-dependency or hysteresis. Or it may reflect network feedback effects propagating financial contagion. Complex systems exhibit tipping points, with small changes in parameter values capable of moving the system from stability to collapse (Anderson and May (1992), Gai and Kapadia (2010), Gai, Haldane and Kapadia (2011)). In complex webs, the failure of two identical-looking banks can have very different implications for financial system stability. The radical uncertainty in such complex webs generates emergent behaviour which can be near-impossible to predict, model and estimate (Haldane (2016)). Third, because they contain human actors whose beliefs about the future shape their behaviour today, financial systems are particularly prone to instabilities and sunspots. If financial market participants are driven by crowd psychology, emotion and narratives, as much as by economic fundamentals and rational calculation, then risks are unlikely to be well captured by standard models (Tuckett and Taffler (2008), Tuckett (2011), Shiller (2017), Bailey et al (2016)). These risks are likely to be highly non-linear, heavily state and time-dependent and thus significantly fat-tailed. out-of-sample tests, unless the sample size is very large.19 That logic is one rationale for the use - and, in some settings, predictive superiority   of the LR in capturing solvency risks. It is a variation of the Brainard (1967) portfolio argument. In this vein, Aikman et al (2014) conduct simulations which demonstrate how simple methods, akin to a leverage ratio, can sometimes dominate complex, risk-weighted approaches to calculating banks  capital requirements when guarding against solvency problems out of sample. This is more likely when the underlying risks are themselves fat-tailed. While complex approaches can appear to perform better For example, DeMiguel et al (2007) find that, for a sample threshold of N = 25, complex rules outperform simple ones only for sample sizes of in excess of 3000 months (250 years) of data. in-sample, simpler approaches may be more robust to out-of-sample structural shifts and fat tails, the like of which we have seen in past financial crises, from railways in the 19th century to subprime mortgages in the 21st. This problem is not unique to banks. Stress tests can reduce reliance on banks  own models. But they then still rely on regulators  risk models, which may be vulnerable to similar issues, especially if they are formulated in an excessively granular manner (Hale et al (2015)). Historically, most banks failures are precipitated by insufficient liquidity. Due to maturity transformation, banks are vulnerable to a sudden withdrawal of funding due to bank-specific or market-wide losses of credibility. In such circumstances, banks will be more robust if they have a buffer of high-quality liquid assets allowing them to meet outflows, survive the first stages of a bank run and, if necessary, giving the authorities time to prepare for resolution. The Basel III LCR was designed and calibrated with these considerations in mind. But excessive maturity transformation can also create risks over longer horizons. This highlights the importance of funding metrics which consider the overall extent to which illiquid assets are supported by unstable sources of funding. If banks are running a high degree of structural maturity transformation, this increases the risk of failure. While one could envisage a range of possible structural funding metrics, including a loan-to-deposit ratio, the Basel III NSFR is designed with these risks in mind. The NSFR speaks directly to a market failure that arises from a market-wide loss of wholesale funding, the like of which was exhibited during the crisis. In this way, it may potentially reduce the probability of damaging asset fire-sales, liquidity hoarding and contractions in lending which may otherwise result. The NSFR is also likely to complement the leverage ratio in acting as a brake on too-rapid balance sheet expansion. The leverage ratio ensures that any such expansion is supported by higher capital. The NSFR ensures any such expansion is supported by more stable funding sources. None of this is to suggest that these risks could not be met with a different, and perhaps smaller, set of regulatory constraints. Cecchetti and Kashyap (2016) have recently argued that the LCR or NSFR may be redundant as one of the constraints is always slack in their simplified bank balance sheet model. Put differently, the existing system of financial regulation may be over-identified. On the other hand, the horizon for assessing banks  liquidity risk may matter. In particular, the LCR and NSFR may complement each other to the extent there are differences in asset liquidity and funding stability at different maturities and that these differences evolve over the cycle. There are conceptual reasons why a portfolio approach to regulatory design, with a small, complementary set of constraints, may have merit in a robust control sense: addressing the different risks facing financial institutions and providing insurance against various uncertainties. Ultimately, however, the extent of over-identification, and any costs it might impose, will depend on the empirical distribution of shocks to banks and the state of their balance sheets at the time. To that we now turn, based on crisis experience. Any counter-factual empirical exercise is subject to huge caveats. Nonetheless, it is revealing to consider experience during the crisis to see what this revealed about the risks banks faced and how different regulatory constraints might have handled them. For example, recent research has found the leverage ratio and structural funding metrics performed well in predicting bank failure during the crisis (Huang and Ratnovski (2009), Demirguc-Kunt et al (2010), Bologna (2011), Arjani and Paulin (2013), Vazquez and Federico (2015)). And Lallour and Mio (2016) find that the NSFR had significant discriminatory power in identifying failing banks during the crisis, after controlling for banks  solvency ratios. This line of research typically deploys regression approaches which weight together the information across different indicators. Here we adopt a somewhat different approach. Specifically, we consider how effective various combinations of regulatory constraints would have had been in identifying banks which subsequently failed during the crisis (the  hit rate ), while at the same time avoiding incorrectly signalling stress among banks which survived (the  false alarm rate ). To do this, we exploit a dataset on the pre-crisis balance sheet characteristics of global banks developed by Aikman et al (2014). The dataset includes almost all global banks which had more than $100 billion in assets at end-2006   116 banks in total across 25 countries. A range of balance sheet metrics are proxied at consolidated (group) level for each of these banks at end-2006. Restricting attention to those banks for which data are available to compute all of risk-weighted capital ratios, leverage ratios and NSFRs reduces the sample to 76 banks. If we focus on risk-weighted capital ratios, leverage ratios and loan-to-deposit (LTD) ratios (as a simplified proxy for the NSFR which captures the ratio of retail loans to retail deposits) the sample size is 96 banks.20 The dataset also includes a liquid asset ratio but this is a relatively poor proxy for the liquidity coverage ratio (LCR), so we exclude consideration of the LCR from this analysis. Because very few banks technically defaulted during the crisis, but many would have without significant government intervention, the metric   the leverage ratio. And using this metric, suppose that we set a cut-off threshold consistent with a particular calibration of that regulatory standard   a leverage ratio of 3%. Now suppose that we have flexibility over the cut-off threshold necessary to achieve a particular hit rate, x. At the same time, we wish to minimise false alarms. As the leverage ratio cut-off increases, the hit rate and false alarm rate must both go up. The key question is by how much each goes up   the relative balance of marginal benefits and marginal costs of hits and false alarms   as the leverage ratio cut-off increases. Charts 17 and 18 plot this for the 76-bank sample.  Chart 17 plots the settings of the leverage ratio needed to achieve particular target hit rates. Chart 18, meanwhile, plots what is referred to as the  receiver operating characteristic  (ROC) curve. Using the sequence of cut-off thresholds for the leverage ratio from Chart 17, this plots the sequence of associated hit rates and corresponding false alarm rates at different settings of the leverage ratio, alongside the 45 degree line which corresponds to the performance of a completely uninformative metric. Two points are clear from these charts. First, it is possible to achieve relatively high hit rates of up to 70% at relatively modest calibrations of the leverage ratio of under 4% and with relatively low false alarm rates of around 30%.  This suggests that, with the benefit of hindsight and abstracting from definitional changes which affect the interpretation of specific numbers, a leverage ratio of around 4% before the crisis would not have been met by around 70% of banks which subsequently ended up failing. It served as a decent signal of subsequent failure. Clearly, such banks might still have failed during the crisis even with a leverage ratio of above 4%. But the low false alarm rate at that calibration, corresponding to the observation that most banks which survived the crisis had a leverage ratio of above 4% going into it, indicates that such a constraint may have helped to curtail their risk-taking, as measured by their leverage ratio, and reduced their likelihood of failure. Second, to achieve high hit rates of above 80%, both the calibration of the leverage ratio and the false alarm rate increase sharply. Achieving a 90% hit rate with a leverage ratio alone requires its calibration to be boosted to around 5.7%. Even then, it comes at the cost of a high false alarm rate of over 80%. In other words, the balance of marginal benefits to costs becomes notably less positive when using a singular instrument if policymakers have a low tolerance for failure. That matters if, for example, the costs of higher capital requirements increase non-linearly (Greenwood et al (2017)). These points are also evident if we assess individually the performance of the RWCR and NSFR. Chart 18 and Table 3 below show that hit rates of 80 or 90% can only be achieved with high false alarm rates and stringent calibrations of these metrics. Overall, each metric individually does somewhat worse than the leverage ratio in balancing hit and false alarm rates. And similar results hold when the loan to deposit (LTD) ratio is considered instead of the NSFR in the wider sample (Chart 19). ###newline###  Now suppose that the regulator can draw on more than one regulatory metric   for example, a LR, RWCR and NFSR. This now requires the setting of three cut-off thresholds and so gives more degrees of freedom. But the objective otherwise remains the same, namely achieving a particular hit rate for signalling bank failures while minimising false alarms. Chart 18 and Table 4 show the results from these multi-constraint simulations. ###newline###  At a target hit rate of 70%, a portfolio of regulatory measures does little better than the leverage ratio on its own in signalling bank stress. At targeted hit rates of over 80%, however, that picture changes. The ROC curve for the regulatory portfolio lies to the left of all those corresponding to individual metrics. In other words, it is possible to achieve lower false alarm rates, for the same hit rate, when multiple regulatory metrics are used. The calibration of each metric in the portfolio is also less stringent than the calibration for each metric individually. These results hold when comparing any pair of regulatory metrics with individual metrics   a higher hit rate per false alarm rate, with less stringent calibrations. It also holds even more strongly in the wider 96-bank sample when the LTD ratio is considered instead of the NSFR (Chart 19). This suggests that, at least in this sample, imposing a small number of regulatory constraints can achieve the same hit rate as any singular constraint, but at a materially lower societal and regulatory cost, as measured by levels of capital and liquidity and/or regulatory false alarms. Intuitively, these results broadly accord with the conceptual discussion. A regulatory portfolio can help when insuring against multiple sources of risk and myriad sources of uncertainty. It also accords with what we know from various individual case studies of bank failure during the global financial crisis: some banks failed because they were over-leveraged, others because their assets were excessively risky, others still because they undertook too much maturity transformation. Because these fault-lines were, for some banks, reasonably well-correlated   their risk management was poor across all dimensions   individual regulatory metrics performed fairly well in identifying these banks prior to them failing. But some banks  risk-management failings were singular, not plural. Their risk blind-spots were idiosyncratic and uncorrelated. By using a portfolio of regulatory stress metrics, it is possible to isolate those banks which were risk-management outliers in one, but not all, dimensions. Consider two very different banks which failed during the global financial crisis. American bank Countrywide had a leverage ratio of 7.7% and a risk-weighted capital ratio of 11.6% at the end of 2006. Even if capital regulation had been much tougher in 2006, it may not have been required to raise capital. But its NSFR was just 0.76, indicative of the structural liquidity risk it was undertaking. By including the NSFR in the suite of regulatory metrics, it would have been possible to capture the risks that Countrywide was undertaking without resorting to materially more stringent capital regulation. By contrast, Belgian bank KBC Group had an NSFR of 1.12, above the current indicative regulatory standard. For that time, it also had a reasonable risk-weighted capital ratio of 8.7%, well above the median capital ratio in the sample. But its leverage ratio was 3.5%. A system of regulation excluding the leverage ratio would have been unable to capture risks of the type KBC Group was undertaking prior to the crisis. The message from this counterfactual exercise, for all its obvious imperfections, is that multiple regulatory metrics may have helped historically in capturing the multiple dimensions of risk and uncertainty exhibited by banks pre-crisis.  With the benefit of hindsight, multiple metrics would have helped identify most failing banks, without either high false alarm rates or potentially punitive calibrations of regulatory standards. While the exercise is based solely on survival and failure of banks during the global financial crisis, it highlights how a small regulatory portfolio beats, counterfactually, a single stock in (systemic) risk and (capital) return terms. As Greenwood et al (2017) argue, multiple regulatory constraints come at a cost by curtailing business models and thus reducing diversity in the financial system. Excessive homogeneity of the financial system can create systemic risks (Haldane (2009a), Wagner (2010)). How much it does so is, however, a matter of degree. If regulatory constraints act as control bounds on structurally defective business models, that strengthens the financial system, even if (indeed, precisely because) it constrains diversity. Empirical evidence suggests this latter effect dominated during the recent crisis. ###newline###  The new architecture has introduced measures which are likely to make for a greater degree of supervisory or policymaker discretion in the setting of regulatory standards.  This arises, most obviously, in the application of supervisory judgement to certain risks that banks face, to stress-testing and to macroprudential policy. Multiple regulatory rules have been augmented with considerable supervisory discretion. Viewed in the round, this new regulatory regime could reasonably be described as  constrained discretion . Regulatory rules provide the constraint within which policymakers exercise discretion. In its broad contours, this new regulatory framework has some similarities with the prevailing monetary policy framework in a number of countries (Bernanke and Mishkin (1997)). These regimes have been found to be an effective way of balancing the pre-commitment necessary to avoid policy time-consistency problems with the flexibility necessary to respond to unforeseen circumstances (Arestis and Mihailov (2009), Borio (2010)). Equally, as in the monetary policy sphere, there is a question about whether this new regulatory regime strikes the right balance between regulatory rules and the degree of discretion with which they are operated. The time-inconsistency problem that pervades the debate over the balance between rules and discretion in monetary policy (Kydland and Prescott (1977), Barro and Gordon (1983)) is arguably even more acute for prudential policy. This is partly because adverse crisis outcomes are highly non-linear and costly, making it more difficult to pre-commit to avoiding forbearance and bail-out. The low probability of crises may also mean that policymakers are insufficiently tough in tackling financial sector risks when times are good and memories of previous crises distant (Reinhart and Rogoff (2009), Malmendier and Nagel (2011), Gennaioli et al (2015)). This can create political pressures to relax regulations to support shorter-term goals. Public choice theory (Olson (1965)) would also suggest that lobbying pressure is likely to be more acute for regulatory policy than for monetary policy. The private costs of regulation are borne strongly by narrow, but powerful, interest groups in the financial industry. And while higher than target inflation is quickly observable, it may be very difficult to judge in real time that regulation is insufficiently stringent given the difficulties of quantifying the probability of future financial crises. These arguments point to the need for strong institutional frameworks, supported by clear mandates, objectives and instruments, to deliver financial stability policy. Indeed, on conceptual grounds, the need for such a framework appears to be at least as strong, if not stronger, than for monetary policy. They also support the case for clarity in the application of these regulatory policies. Not least given its newness, there may be further to go clarifying the motivation behind macroprudential interventions and the circumstances which might justify different macroprudential instruments - in short, in defining and refining the macroprudential policy reaction function. The UK s Financial Policy Committee has made some progress in this area, most notably in setting out its strategy for using the countercyclical capital buffer (Bank of England (2016a)). A discussion of the principles underlying the UK s approach to macroprudential policy can be found in Brazier (2017a). The benefits of pursuing this path are clear from monetary policy experience (Brazier (2015)). Increasing the predictability of policy can enhance the ex-ante signalling and expectations channels of regulatory policy, as has been achieved in relation to monetary policy (Bernanke and Mishkin (1997)). It enhances ex-post accountability to stakeholders, political and societal. And it reduces the potential behavioural biases otherwise associated with discretionary decision-making and which have been found in the past to affect discretionary regulatory policy, including regulatory capture (Dal B  (2006)) and defensive decision-making (Gigerenzer (2014)). At the same time, there is clearly a balance to be struck. As Greenwood et al (2017) argue, strict rules-based systems are likely to be arbitraged and exploited by banks. For example, recent theoretical work and experimental evidence suggests remuneration contracts can be restructured to recreate the excessive risk-taking incentives that new rules seek to reduce (Thanassoulis and Tanaka (2017), Harris et al (forthcoming)). These arguments make it difficult to specify strict regulatory rules for all seasons. They point to the need for a forward-looking, horizon scanning approach with scope for supervisory judgement and macroprudential discretion (BCBS (2017)). This does not, however, obviate the potential benefits from seeking, over time, to specify clearer mandates and regulatory reaction functions, especially on the macroprudential front. ###newline###  The empirical exercise in the previous section looked at how a set of regulatory standards, applied counterfactually, might have done in spotting stress among a set of banks. Plainly, any such counterfactual exercise is subject to significant caveats. The most important of these is that it cannot take account of how changes in the regulatory regime might themselves have reshaped risk-taking incentives at the time. This Lucas Critique plainly looms large in the field of financial regulation. Financial regulation, like any tax, is very likely to change the behaviour of the party subject to it. This is neither surprising nor, necessarily, undesirable. Indeed, sometimes it is the precise purpose of the regulation in the first place. For example, average risk weights on assets held in the trading book have increased by 45% across a sample of major UK banks between 2006 and 2013. Partly in response, trading books have shrunk by, on average, 24% across these banks and by 45% across the world s G-SIBs. This was an intended, and probably desirable, behavioural response to a necessary recalibration of regulatory standards. That is not to say, however, that all behavioural adjustments are either exactly as intended or desirable. This is particularly the case when these responses seek to avoid regulation entirely   so-called regulatory arbitrage. Risk, like energy, does not disappear into the ether. It is typically conserved, at least to some degree. In response to tighter financial regulation, risk is likely to change shape or location, often both. Pre-crisis, both incentives were at play, albeit to differing degrees in different parts of the global financial system. In the US, where a leverage ratio was in operation and often the binding constraint, there were incentives for banks to seek higher-risk assets rather than expand balance sheets (Chart 20). In Europe, without a leverage ratio but with risk-based capital standards, there were incentives for banks to expand balance sheets and shade downwards risk weights. Canadian banks  incentives sat somewhere in between. Some recent studies have looked at these behavioural shifts in greater detail. During the euro-area crisis, banks increased their exposure toward higher risk government bonds, which carried no capital requirement (Acharya and Steffen (2015)). And following the Lehman crisis, German banks reduced their corporate lending less when the capital requirement was set under the standardised approach (Behn, Haselmann, Wachtel (2016)). In the UK, higher risk mortgages shifted towards lenders whose capital requirements were less risk-sensitive after the introduction of Basel II (Benetton et al (2017)). Recent research has considered how the leverage ratio announcement affected behaviour among a panel of over 650 European banks (Acosta-Smith et al (2017)). It finds a significant increase in risk-taking among those banks for whom the new regime was a binding constraint. This risk-taking was greater, the further these banks were from meeting the new 3% threshold: banks with leverage ratios of 1.5%, 2% and 2.5% were found to increase their risk-taking by 3.4, 2.3 and 1.1 percentage points of risk-weighted assets respectively. This is clear empirical evidence of the risk-shifting channel at work. This is only, however, one side of the risk equation. There were two mitigating factors on the other side. First, a rise in the leverage ratio also boosts these banks  capital. Once translated into default probabilities, Acosta-Smith et al (2017) find that the second effect swamps the first: a one percentage point rise in the leverage ratio raises the odds ratio (on banks being in distress versus safe) through risk-shifting by 1-3.5%. But the reduction in the odds ratio from lower leverage is close to 40-50%. Second, the leverage regime is not a replacement for the risk-weighted capital regime but an addition to it. The capital regime places an automatic upper-bound on the extent to which banks can increase their risk-weighted assets. In other words, the capital ratio regime places constraints on incentives to risk-shift. Conversely, the leverage ratio can serve as an effective constraint on incentives to game or shade risk weights. Risk-taking incentives are, in effect, book-ended by the leverage and capital constraints. There are other means of constraining adverse incentives. Incentives to game risk weights can be constrained by imposing floors and/or by using standardised approaches for certain categories of assets.22 Some countries already make use of such approaches, including the US, the UK, Germany, France and Spain. The stress-testing regimes operating in a number of countries are also a way of cross-checking, and backstopping, the models used by banks. In a world of uncertainty as well as risk, having this portfolio of approaches for dealing with avoidance incentives - some discretionary, others rule-like - makes sense. Evidence on the incentive effects of financial regulation is almost always drawn from looking at banks  experience either side of a change in policy. By then, however, any unintended or undesirable consequences of this change will already have been felt. Regulatory policy is in a perpetual catch-up loop, the bloodhounds in pursuit of the greyhounds. In an ideal world, it would be possible to gauge in advance how a regulatory change may reshape incentives, in particular risk-taking or regulatory-avoiding incentives. One approach to doing so is to use experimental methods. Experiments have previously been used to examine how different pay structures affect loan officers  risk assessment and lending decisions (Cole, Kanz and Klapper (2015)). They have also been used to examine the effect of specific interventions on behaviour in other areas of public policy (Halpern (2015)). Recently, the Bank of England has conducted a lab experiment to assess how the design of pay regulation may affect risk-taking behaviour and project search effort (Harris et al (forthcoming)). Specifically, the experiment was designed to examine how caps on bonuses and  malus  (bonuses that are not paid out if, for example, performance falters in subsequent years) might affect individuals  risk choices and efforts to seek out the best projects. The experiment showed evidence that, while both schemes tend to reduce risk-taking, they could be arbitraged relatively easily by introducing absolute or relative performance targets. There was also some evidence that a bonus cap might reduce incentives to search for good projects. The Bank of England is considering extending this experimental approach to a wider range of policy design questions and a wider range of financial market participants - risk-takers and risk-managers. In principle, this approach might provide some early indications of how new regulation might reshape risk incentives, including arbitrage incentives, which could help in recrafting regulation before it is introduced. ###newline###  One of the greatest intellectual errors made in the run-up to the crisis was a classic  fallacy of composition : it was assumed that the resilience of individual financial institutions was both a necessary and sufficient condition to ensure the resilience of the financial system as a whole. Events during the crisis, and subsequent theoretical and empirical work, has shown that the resilience of individual firms is neither necessary nor sufficient for the mitigation of systemic risk (Masera (2014), Crockett (1996)). Out of this intellectual vacuum, a new framework for regulation has been born   macroprudential regulation. This explicitly recognises the links that might tie together individual nodes in the financial system. These might arise from correlated asset exposures, the type of which has historically emerged during the upswings and downswings of the credit cycle (Aikman et al (2015)). Or they might emerge from financial exposures, on- or off-balance sheet, between intermediaries operating in the global financial web (Haldane and May (2011), Arinaminpathy, Kapadia and May (2012)). Over the past decade, a lot has been written in the area of macroprudential policy (Galati and Moessner (2013), Aikman et al (2013), Freixas et al (2015)). A sizeable number of countries are now undertaking macroprudential policy in some shape or form. Table 5 in the Annex provides a rough summary of current international macroprudential practices (for a more comprehensive overview, see Cerutti et al (2017)). By any historical metric, however, macroprudential policy remains a fledgling framework. Understandably, many of its key facets remain contentious. And the macroprudential policies put in place internationally so far are more notable for their differences than their similarities. This is providing a diverse body of case law. We discuss two key aspects of this framework: its appropriate objectives; and the choice of instruments. The subsequent academic literature has usefully refined how we think about these goals of a macroprudential regime. One fruitful strand has focused on the pecuniary externalities generated by fire-sales in asset markets (Lorenzoni (2008), Jeanne and Korinek (2010), Bianchi and Mendoza (2010), Benigno et al (2013)). Collateralised borrowing leads to externalities because individual borrowers do not internalise the fact that increasing debt in good times raises the likelihood they will be forced to sell assets following adverse shocks, pushing prices lower, tightening collateral constraints and exacerbating downturns. These feedback and amplification loops can mean that private borrowing in good times is greater than a social planner would choose, facing the same constraints. That is the theory. Experience during the crisis tends to support the importance of these transmission channels. When highly-levered banks were forced to sell illiquid assets at highly discounted prices, this lowered valuations further and tightened constraints for other banks (Brunnermeier (2009)). This contributed to the depth and duration of the economic downturn. In a similar spirit, Braun-Munzinger et al (2016) develop an agent-based model of the corporate bond market comprising a market maker, fund traders and fund investors. They find that funds pursuing similar trading strategies can exacerbate price movements and contribute to the pro-cyclicality of financial markets. Additionally, the growth of passive investments may have both positive and negative effects on volatility: they decrease yield volatility on average, but can increase the likelihood of large dislocations after shocks. While this fire-sale mechanism applies most directly to financial intermediaries with marked-to-market balance sheets, and funds that can be redeemed at short notice, a similar dynamic can operate if there are forced sales by owners of, or investors in, real estate who are credit-constrained borrowers. This, too, can drive prices lower in a feedback loop. Some of these mechanisms were in play recently among UK real estate investment vehicles following the EU referendum result (Bank of England (2016b)). A related, but distinct, mechanism through which financial frictions can affect the wider economy is through aggregate demand externalities. In Korinek and Simsek (2016), credit-constrained households de-lever sharply when an adverse shock hits. If the shock is large enough, the resulting fall in aggregate demand can push the economy into a liquidity trap with interest rates constrained at the effective lower bound. In this environment, macroprudential policies that slow the build-up of household leverage ex-ante can be welfare-improving in avoiding this outcome. Farhi and Werning (2016) also offer a model of macroprudential policy in the face of aggregate demand externalities. risk-taking, especially as memories of past financial crises fade (Guttentag and Herring (1986), Herring (1998), Haldane (2009b), Gennaioli, Schleifer and Vishny (2012)). And such behaviour might be amplified by contracts that reward short-term performance excessively and by herding in financial markets (Avery and Zemsky (1998), Lakonishok et al (1992), Bikhchandani and Sharma (2001)). Aikman, Nelson and Tanaka (2015) show how reputational concerns and peer benchmarking can drive credit cycles. in spending following the financial crisis. And Bailey et al (forthcoming) exploit Facebook data to identify how social interactions can drive contagious risk-taking in the US housing market. In summary, the market failures associated with fire-sale externalities and behavioural tendencies which can drive short-termism provide a strong case for a macroprudential regulator with an objective of preserving the dynamic resilience of the financial system, both among banks and, prospectively, among non-banks. No less compelling, however, is the evidence, both micro and macro, linking credit booms to aggregate demand externalities. That, in turn, provides a rationale for pre-emptive macroprudential interventions to avoid excessive inflation of credit and asset prices in the first place. The Bank of England s second public foray into the macroprudential policy debate was a 2011 discussion paper on elements of the macroprudential toolkit (Bank of England (2011)). That paper described 12 distinct macroprudential tools (see also CGFS (2010, 2012), Hanson et al (2011) and ESRB (2015) for discussions of macroprudential instruments). The majority of these targeted different aspects of banks  balance sheets including: the countercyclical capital buffer (CCyB); sectoral capital requirements (SCRs); leverage ratio buffers; dynamic provisions; and liquidity buffers. Other potential macroprudential instruments included those aimed at influencing lending standards - for example, through setting loan to value limits (LTV), loan to income limits (LTI) or margining requirements on collateralised borrowing in financial markets. A third set of potential instruments focused on making market infrastructures more resilient and improving financial market practices   for example, by mandating central clearing, through trading venue design and through enhanced disclosure requirements. At the other end of the spectrum is the CCyB. That has only been used by 6 countries to date. This is surprising given that it is the only tool that has a well-defined operating framework internationally and which includes jurisdictional reciprocity. A potential explanation is that the Basel guidelines suggest the buffer should be activated when excess credit growth threatens an increase in system-wide risk. The majority of advanced countries have not come close to experiencing aggregate credit booms in the post-crisis period. There is also relatively little guidance from the literature on tool strategy, selection and interaction. One exception is work assessing the role of monetary policy in leaning against financial cycles. A paper by the Federal Reserve Board (Ajello et al (2016)) analyses the costs and benefits of using interest rates to lean against vulnerabilities in the financial system. In the baseline calibration of their model, the costs of using monetary policy in this way are large relative to the benefits: the optimal adjustment in interest rates in the face of financial stability risks is in the order of 3 basis points. While the adjustment to interest rates can be larger   up to 75 basis points - if alternative assumptions are made about cost of crises and the sensitivity of crisis risk to monetary policy, the calibrations required to deliver these outcomes are extreme. Svensson (2017) argues that the costs of using interest rates to lean against financial crisis risk are likely to be greater still if one takes into account that doing so will make the economy weaker at the point a crisis strikes and hence might actually worsen its severity. extremely persistent. But the general consensus is against deploying monetary policy, at least in an activist way, for financial stability purposes given its limited efficacy and potential real-economy costs. The dashed lines show the steep trade-off facing a policymaker with a monetary policy tool only. Attempts to reduce the crisis probability with higher interest rates entail significant costs for current output and inflation. The solid lines show how this trade-off improves when the CCyB is added to the instrument set, even under conservative assumptions about the impact of the CCyB on the economy s productive capacity.  The variation in the CCyB required to deliver these benefits can be large. Given the historical distribution of shocks, the standard deviation of the CCyB is around 2 percentage points. A final strand of the literature has analysed whether the presence of macroprudential policy gives rise to coordination problems with monetary policy. For example, De Paoli and Paustian (2017) study a non-cooperative game between monetary and macroprudential authorities and find coordination problems to be significant following cost-push shocks in cases where objectives do not overlap. But they also find that a leadership structure in which macroprudential policy moves first   or is varied at a lower frequency than monetary policy given that financial vulnerabilities build slowly   mitigates these coordination problems. ###newline###  Financial regulation has undergone a fundamental rethink and reform since the global financial crisis. By most accounts and on most evidence, that has resulted in a financial system which is more resilient than in the past, better equipped to head-off market frictions and failures of various kinds, better attuned to various adverse incentive effects, and better able to safeguard risks which imperil the financial system as a whole. It is a regime of  constrained discretion , comprising a portfolio of regulatory measures calibrated, albeit roughly, to equate societal costs and benefits. That s the easy bit. The hard bit is what happens next. Not least given the scale of regulatory change over the past decade, this new regulatory framework will plainly need to adapt in the period ahead in the light of the new evidence, experience and incentives associated with operating it. This paper has discussed some of those issues. From a potentially very long list, we conclude by highlighting some of the areas where we think further research and practical exploration might be useful in the future debate on regulatory reform.25 Optimal Levels of Capital: One of the most animated, on-going areas of regulatory debate is whether capital standards have been appropriately calibrated. Relative to the pre-crisis LEI study, current levels of capital requirements in most countries are below that calibration. The single most important reason for that is because the LEI study did not take into account the potential impact of non-equity sources of capital, specifically TLAC, in reducing the impact and probability of crisis. The key question, then, is whether these instruments prove to be as loss-absorbing in future situations of stress where bail-in becomes necessary. This issue is particularly relevant when it involves systemically-important institutions or sets of institution, when the costs of bailing-in (and bailing-out) are large and lumpy. At this early stage, the jury must still be out. On the one hand, historical evidence on bailing-in different types of notionally loss-absorbing bank liabilities in situations of systemic stress has not been encouraging, reflecting the acuteness of the time-consistency problem facing the authorities in these cases. On the other, new statutory resolution arrangements are much stronger than ever previously, and statutory TLAC requirements are now prescribed in advance. This means next time could plausibly be different. Given its importance to the overall capital calibration, this issue deserves further empirical and theoretical consideration. Multi-Polar Regulation: The new regulatory framework is a different beast than its predecessors in terms of the number, complexity and discretionary nature of the constraints it imposes. There are good conceptual and empirical grounds for such a portfolio approach in insuring against future risks and, in particular, uncertainties. And from a risk- and uncertainty-averse social welfare perspective, even a marginally over-identified system might, in general, be preferable to a marginally under-identified one, if recent crisis experience is any guide. Indeed, that is the essence of robust control. Ultimately, however, the past is another country. There are legitimate questions to answer about whether multiple regulatory constraints could lead to excessive homogeneity and inefficiency in the financial system. And arbitrage is an ever-present threat, even with multiple regulatory metrics. This is an area where further research and practical experience with operating the new regime will be essential in gauging whether there is scope for streamlining, provided the resulting regulatory regime remains robust to the radical uncertainty that necessarily affects any complex, adaptive system such as finance.26 Models of Financial Stability: In a world of monetary, macroprudential and microprudential policy, all having an impact on the economy and on the financial system, there is an increased onus on developing quantitative frameworks which enable us to understand their impact, individually and collectively, and their interaction (Bank of England (2015b)). That calls for models able to capture quantitatively monetary, financial and regulatory channels of transmission and the feedback mechanisms between them. Progress has been made, in particular since the crisis, in developing macro-models with an explicit financial sector which can capture rich, two-way feedbacks between the economy and financial system (for example, Brunnermeier et al (2012), Brunnermeier and Sannikov (2014)). There has been progress, too, in developing models of systemic risk which assign macroeconomic factors, and within-system feedbacks, a prominent role (Greenwood et al (2014), Cont and Schaanning (2017)). Yet we are still probably in the foothills when developing a unified framework for bringing these factors together in one place, a framework that could capture the rich feedback and amplification mechanisms that operate in practice and a model which could then serve as a test-bed for each of the three arms of policy. Indeed, it could be that a single, Holy Grail, framework is infeasible or indeed undesirable. Market-Based Finance: The emergence of a large and diverse shadow banking system, both prior to the crisis in the US and subsequent to it elsewhere around the world, plainly poses both considerable opportunities and potential threats to financial stability. So-called market-based finance provides the financial system with a second, non-bank, engine on which to fly which could be beneficial in a diversity For example, the results of the Bank of England s 2014 stress test found that risk-weight procyclicality was a significant contributor to the change in capital ratios in the stress test scenario (Bank of England (2014)). sense. Nonetheless, it also gives rise to potentially new sources of systemic risk and contagion, as risks change shape and location. The FSB has made significant progress in progressing the regulatory debate on such matters (FSB (2017e)). Certainly, these trends carry implications for both the conduct of regulation and for central bank procedures. A world of greater market and liquidity risk may call for different sets of regulatory instrument than the bank-based solvency and liquidity metrics of Basel III. Market-based instruments, such as margin requirements, may have a greater role to play (see, for example, ESRB (2017)). It may also call for different types of market intervention by central banks   different markets, different instruments, different counterparties. The crisis has already seen a mini-revolution in the design of liquidity facilities by central banks. As the financial system changes shape, it seems plausible to think that further change could be necessary. If so, that change would benefit from further research on the costs and benefits of the extended regulatory and central bank safety net. The direction of travel, over time, probably needs to be towards somewhat clearer constraints, and somewhat more circumscribed discretion, if macroprudential regimes are to be effective, robust and transparent. Political Economy of Financial Regulation: The scope and range of regulatory responsibilities assigned to central banks and regulators have expanded materially during the course of the crisis. Accompanying that, some of the new regulatory requirements and practices put in place are quite discretionary in nature, including stress-testing and some other macroprudential measures. A number involve regulators making overtly distributional choices, for example around access to credit. This takes central banks and reguIators more explicitly into the political-economy realm than at any time in their recent (and perhaps distant) history. It has probably also contributed to some people questioning the appropriate scope of central banking, its degree of independence from the political process and from wider society and appropriate accountability mechanisms.  There is a debate to be had, an analytical debate, about the appropriate degree of discretion to confer on regulators, to ensure they retain the flexibility they need to respond to events while ensuring their decisions are clear, transparent and unpolluted by behavioural biases and time-inconsistency problems. There are also interesting issues to explore about how regulators explain and account for their decisions to wider society, particularly when they have strongly distributional consequences. This is clearly unfinished business. The Contribution of the Financial System to the Economy and to Society: One of the striking features of the past several decades has been the rising share of financial services in measures of economy-wide value-added and, in tandem, rising financial sector balance sheets as a fraction of GDP in a number of economies. Sometimes this goes by the name  financialisation . There are good reasons to think increasing financial depth is a natural feature of economies as they grow and develop. Indeed, there is a fairly well-established literature quantifying the boost to growth and productivity which arises from financial depth, especially for developing countries (Levine et al (2000)). Latterly, however, the question has been asked whether it is possible to have too much of a good thing. Some have asked why the cost of financial intermediation continues to rise and what this might signal about the efficiency of financial services as an industry (Friedman (2009), Philippon (2015)). Others have pointed to a possible U-shaped relationship between measures of financial depth and productivity and growth (Cecchetti and Kharroubi (2012), Heil (2017)). These questions have an important bearing on the contribution the financial system makes to the economy and to society. They are also meta-questions for regulatory policy. They warrant further research. Financial Stability Implications of FinTech: Technologically-enabled innovation in financial services, or FinTech, has grown rapidly in recent years. The FSB s recent report contains a useful taxonomy of such innovations (FSB (2017f)). With this development comes the promise of greater consumer choice, improved access to credit for some borrowers, and greater efficiency and productivity in the traditional intermediary sector. There are also potential resilience benefits from increasing diversity in the provision of financial services (Carney (2017a)). While the sector is probably too small at present to pose a threat to financial stability, there is ample historical experience of risks emerging rapidly in fast-growing sectors if left unchecked. Such future risks might include: conventional vulnerabilities associated with excessive use of leverage and maturity, liquidity and credit transformation; the emergence of new highly-interconnected entities; and cyber and other operational risks. There is also the potential for these developments to make traditional universal banks less resilient, if they are forced to rely on less stable funding sources, for example. A challenge for policymakers is to ensure that the regulatory regime, and the wider policy framework   including the scope of central banks  liquidity facilities   adapts to keep pace with these developments (Lagarde (2017)). ###newline###  International Financial Reporting Standards (IFRS) were adopted for the end-2005 accounts. The end-2004 accounts were also restated on an IFRS basis. The switch from UK GAAP to IFRS reduced the capital ratio of the UK banks in the sample by approximately 1 percentage point in 2004. ###newline###  Data as of end-2007. Sample includes Bank of America, Barclays, BMO, BNP Paribas, BONY, CIBC, Citigroup, Cr dit Agricole, Credit Suisse, Deutsche Bank, HBOS, HSBC, JPM, Lloyds, NBC, RBC, RBS, Santander, Scotiabank, Soci t  G n rale, State Street, TD, UBS, UniCredit, Wachovia, Wells Fargo.