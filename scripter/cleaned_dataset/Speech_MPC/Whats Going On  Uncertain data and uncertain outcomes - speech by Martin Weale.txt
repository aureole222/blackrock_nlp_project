 I am grateful to Stuart Berry, Philip Bunn, Alan Castle, Shiv Chowla, Jonathan Fullwood, Marco Garofalo, Tomas Key, Jeanne Le Roux, Alan Mankikar, James Mitchell, Andre Moreira, Lee Robinson, Matt Swannell, James Tasker, Ken Wallis and Abigail Whiting for helpful discussions and support, and to my colleagues on the Monetary Policy Committee and at the Bank who provided valuable comments on an earlier draft. ###newline###  I thought that quoting Mr Wilson, a local MP as well as Prime Minister, in his centenary year would be an appropriate way of introducing a discussion of some of the practical difficulties faced by monetary policy makers. First, however, let me assure you that, unlike Mr Wilson, I am not going on; I have been lucky to have enjoyed three opportunities to visit Liverpool during my time as a member of the Monetary Policy Committee, but this will be the last. In early August I will be replaced on the Committee by Michael Saunders, from Citigroup, to whom I offer my congratulations. Descriptions of the monetary policy making process often invoke various vehicle-driving analogies, with monetary policy decisions being seen as applications of the accelerator or brake that aim to keep the economy on track. Unfortunately, as many people have previously noted, these sorts of analogies are misleading for several reasons. The one on which I would like to focus today is that, compared to the drivers of most vehicles, the MPC is much less certain about how fast the economy is currently moving, or even how fast it was going in the recent past. Put another way, unlike Mr Wilson, while we do our best to form judgements about what is going on in the economy, I would never make the claim that we  know  what is going on. There are always degrees of uncertainty about both the data and their interpretation. I would like to discuss today some of the means by which we try to minimise that uncertainty and also the ways in which we try to express the limits to our knowledge. I will begin with some of the perennial challenges that the MPC faces before focussing on present sources of uncertainty. So first I will talk about how we try to estimate the state of the economy ahead of any official data. Secondly I will take a fresh look at the relationship between the first official estimates of GDP growth and final estimates of growth. I will follow this by offering my own thoughts on how the Committee might represent the uncertainty surrounding its forecast before proceeding to discuss some particular sources of uncertainty at present. ###newline###  How fast the economy is currently growing might seem a simple question to ask. The answer is anything but straightforward. The Committee needs to make decisions as things happen, but data become available only with a lag. The Office for National Statistics is faster than most statistical offices at producing estimates of economic growth, but their first estimates appear only about four weeks after the end of the quarter to which they relate. And those estimates, like those produced by other countries, are subject to substantial revision. In the short term, therefore, we face the problem of estimating the current state of the economy.  Nowcasting , as this process is commonly known, the growth rate of GDP can be done both using forecasting methods   e.g. producing estimates of GDP on the basis of the most recent solid economic data available   and by using those data which become available during the quarter in question. Not surprisingly there is a preference for relying on current information as providing an indicator of what is going on at the moment and this comes in two forms: business surveys and the accrual of official monthly data. Business surveys are a popular and widely-used type of current information on which a great deal of attention is focused. These are compiled by bodies such as the British Chambers of Commerce (BCC), the Chartered Institute of Procurement and Supply (CIPS) and the Confederation of British Industry (CBI). Typically a relatively small number of businesses are approached and respondents are asked to provide qualitative answers to a range of questions. The questions of most interest to the Committee are about the recent, and expected future, growth rate of firms  output. Attention usually focuses on a balance   the proportion of respondents who report an increase in output less those who report a decrease. The outperformance of the Bank s nowcast is, in fact, stronger than simple visual inspection suggests. The nowcast is published in each Inflation Report, which is produced less than half way through the quarter, while the survey measure, in contrast, is the average of the three monthly surveys and is not available until the end of each quarter. I currently take modest reassurance from the fact that our nowcast is for growth of . per cent in the current quarter, whereas the most recent CIPS figures have been widely quoted in the press as implying growth of . per cent. The nowcast estimate is, however, an estimate of the final figure and, as I will show later, outside the abnormal period of the recession of /, low initial estimates are prone to upward revision. So the initial estimate may well be lower. On top of this, of course, over the period from Q to Q the root mean square error of the nowcast is . per cent, suggesting that there is only about a chance of two out of three that the outcome is within . per cent of the nowcast value. The margin of uncertainty is quite wide. I will not fall into the linguistic trap of suggesting that nowcasting is difficult   it is not. But it is inexact. We cannot be precisely sure of what is going on as we make our decisions and produce our forecasts. Indeed there has to be quite a high chance that the figure deduced from the CIPS data is in fact closer to the ONS preliminary estimate than is our own figure. There is equally, of course, quite a high chance that things are materially better than these figures suggest. ###newline###  There is nevertheless a question of why business surveys do not do better as indicators of the state of the economy, or equally a question of whether they could be designed so as to do better. In order to explore this question my colleague, Tomas Key, and I have constructed a  synthetic  business survey from the monthly data that firms provide to the Office for National Statistics, which it uses to compile its estimates of GDP. We categorised each firm's output as up, no change or down on the month, and then compared the balance of these  responses    the proportion of firms reporting up relative to the proportion of firms reporting down   with the movements in output directly implied by the figures. This allows us to see how much information is lost by moving from a quantitative to a qualitative measure of output growth. The answer is that, with an optimally designed survey, the loss of information is minimal   the survey balance has a correlation with the actual data of only just less than one. By an optimally designed survey, I mean a survey that asks firms whether their output has grown above a certain threshold, declined below a certain threshold or has grown by an amount in between these two. The thresholds that we have found to be optimal are quite wide, +/- %, and considerably wider than the thresholds of +/- -% that firms themselves have typically told the CBI answering practices survey that they are using. If we examine the information loss from a survey with these thresholds, the loss is greater, but the correlation with the actual data is still around .. It therefore seems likely that it is not the fact that business surveys are qualitative that reduces the quality of the information that they provide, but other factors. One is that the only way that business surveys can be timelier than the ONS estimates is if they have smaller sample sizes, which will necessarily reduce the quality of the signal that they provide. Another is that firms often do not answer the surveys in the exact way that they are asked to. For example, Lui, Mitchell and Weale () have found that firms  answers to the CBI s Industrial Trends Survey about growth in output over the last three months contain information from up to six months in the past. There is, however, an additional factor which explains why surveys do not do better. They do not cover the output of the public sector, which is an important part of GDP and there may be some other sectors where coverage is relatively limited. So, while it may be possible to improve on their design, the gain in performance which it seems could be delivered by improving the surveys would take us only so far. ###newline###  Producing an estimate of economic growth ahead of the first official estimate is only one stage in our process of trying to form a view as to what is going on. Official estimates of the national accounts, and in particular real GDP, are subject to considerable revision or, as I prefer to call it, updating. This should hardly be a surprise. After all policy-makers like the members of the Monetary Policy Committee want data to be up to date. But data are collected from a range of sources and some of these become available only with a considerable delay. As you know, GDP can be estimated from the output of businesses, the expenditure of households, firms and the government or from measures of income. These three different measures give different answers, and current thinking is that the most accurate estimate of GDP is obtained from measures of income computed from tax data. In the nature of things, however, these tax data are available fully only after people have completed their tax returns and this is often not done until the January following the end of the financial year in question. A first estimate of the output measure is available, in contrast, less than a month after the end of each quarter in question; even this is, however, subject to revision because the preliminary estimate is computed, as it needs to be, from an incomplete sample of returns. As later data are included the number is quite rightly revised. There are further revisions as adjustments are made to align the output and expenditure measures with income estimates as they become available. For the user of data, this then raises two questions. First of all, how good is the preliminary measure as a predictor of the final measure, taken here to be the estimate published after three annual cycles of revision? Secondly, how far can one predict the revisions to the preliminary estimate, and in particular, are business surveys of any help in that regard? Chart  shows the preliminary estimate of growth plotted against the final estimate of growth for calendar quarters from Q to Q, the last quarter for which we have a final estimate. I have also estimated the regression line linking the two, and this is shown in the chart. If the preliminary estimate is a good estimate of the final estimate we should expect the coefficient in the regression equation to be close to one and the constant term close to zero. That does not say that the numbers are perfect; revisions still happen. But it does suggest that there is no systematic bias in the initial data. The regression equation seems satisfactory, and a formal statistical test suggests that I cannot reject the hypothesis that the slope coefficient is one with a constant of zero   the p-value is .. Unfortunately that is not the end of the matter. The diagram shows a classic pitfall of careless applied work. I have plotted in red the observations for the period Q to Q, the period of sharp economic contraction. You can see that three of these stand out very sharply from the rest of the pack. In such circumstances regression analysis can be highly misleading. The outliers exert a very great deal of influence on the estimates of the slope and constant; to be confident in the conclusions one would want to be sure that they did not depend on the inclusion of these recession data. You can see, in Chart , that when I leave out the four outlying quarters of the recession, a very different picture emerges. The slope coefficient is well below one and the constant term is materially positive. If I test the hypothesis that the slope is one and the constant is zero then, with these observations, the probability of that being true is less than . per cent; in other words, the statistics are saying that we should rule it out as being rather unlikely. I am, in effect, arguing that the measurement issues which arise during sharp contractions, like the period from Q to Q are different from those which arise in more normal times. That might raise the question whether the new, post-recession revision pattern is different from that found before the recession. The answer to this seems to be no, or at least not materially. If I look at the period before the crisis, I find a slope of . and a constant of ., while for the period after the crisis, the slope is . and the constant .. A formal statistical test suggests that I cannot reject the hypothesis that these are equal   the p-value is .. So, while many things are different now from before the crisis, it is not obvious that the relationship between preliminary GDP and final GDP has changed. The stability of this relationship might come as something of a surprise. However, as I show in Appendix A, this is a natural consequence of producing estimates from incomplete data. They are likely to exaggerate movements in both directions. The framework that I set out in the Appendix assumes that the economy can be split into two sectors, sector A and sector B. The first estimates are produced using only data for sector A because those for sector B are not yet in. Plainly a better first estimate could be produced if, in addition to the hard data for sector A, a good forecast is used for sector B. On the other hand, if the forecast for sector B is not very reliable, then it may be better to rely just on the forecast for sector A and make an adjustment on the basis of the regression equation that I have set out above. The approach used by the MPC to adjust ONS initial estimates (Cunningham et al., ) makes heavy use of business surveys I suppose I like to think of it as constructing a substantial infrastructure to forecast the output of sector B, at least when applied to the ONS preliminary estimate of GDP growth. In practice of course, because we cannot see, in the ONS release, separate growth rates for sector A and sector B, it simply produces an estimate based on the initial estimate of GDP, together with past estimates and additional data provided by business surveys. For today s purposes I would like to keep it simple. In Table , I show, as model , a regression equation estimated for the period before the crisis, with final GDP growth as the dependent variable and the preliminary estimate as the explanatory variable. Model  includes a composite balance constructed from the CIPS surveys as an additional explanatory variable. Neither t-statistic is significant at five per cent, pointing to a problem of collinearity; the survey data and the preliminary estimate are highly correlated. Model  is the sort of model which would be used by someone who believed that ONS first estimates were no good. It relies only on the CIPS balance and has a slightly larger standard error than model . How well do each of these work in the period after the crisis? Model  gives an out of sample root mean square error of .. Model  gives an error of . while model  gives . for the same period, which is larger than the root mean square revision of .. The root mean square error of the backcast published in the Inflation Report is ., so, at least over this period, models  and  perform better. That does not, of course, mean that the MPC s approach will always be worse than model  or model , or indeed that model  will always perform better than model . The conclusion I would draw from this is simply that I should view cautiously any claim that business surveys provide helpful information about the current state of the economy, over and above what the ONS can tell us in the preliminary estimate. At the same time, of course, it is even more important to remember that equations such as model  and model  do not provide the exact answer. The root mean square errors suggest that only about two thirds of the final estimates will lie within . percentage points of the backcasts that they can generate. We cannot be sure of what is going on, even when we have initial ONS estimates of economic growth. ###newline###  The assumption that errors are normally distributed is widely made and has many convenient properties. It leads, for example, to the conclusion that the mean is the best summary statistic indicating the location of the distribution, while the standard deviation is the best summary statistic for showing the dispersion of the distribution. As was noted during the financial crisis, it tends to imply that realisations a long way from the mean will occur only rarely. The Committee s experience was that large forecast errors occurred more frequently than my predecessors had thought likely. In one sense this does not matter; the fan charts represented the subjective judgement of the Committee. One might, nevertheless, hope for some coherence between subjective judgement and subsequent realisation, and the Bank s Independent Evaluation Office carried out statistical tests which suggested that the forecast errors were distributed materially differently from anything coherent with the ex ante judgement of the Committee (Independent Evaluation Office, , p.). Chart  shows a histogram which displays our actual forecast errors for the level of GDP two years ahead for the forecasts produced from Q to Q. Here, and in all subsequent charts I am showing the errors relative to the modal forecast, because the focus of my discussion is on the distribution around this rather than on the position of the mode. You can see that the errors tended to be clustered between - per cent and  per cent. However, the Committee, like everyone else, failed to forecast the recession of / and this led to a slew of very large forecast errors. There are in fact six out of sixty-four errors larger than three percentage points and these all happened at the time of the recession. But you can see that, even without these errors, the histogram gives a sense of a downside skew. This largely reflects the disappointing growth the United Kingdom experienced during my first three years on the Committee, as the crisis in the euro area spilled over to the United Kingdom. There are however, two issues arising in fitting the pattern of forecast errors shown in Chart . First of all, the forecast periods overlap with the implication that forecast errors are likely to be serially correlated; I have not made any adjustment for this here. Secondly, the forecast errors for the / recession have a very profound influence on the structure of the distribution that can be fitted, notwithstanding that the t-distribution is less affected by outliers than is the normal distribution. It seems to me reasonable to downweight their influence, although I would be reluctant to suppress it completely. What I have done is to construct a synthetic series of forecast errors which comprises three sets of data   the actual series plus two sets of this series with the six largest errors excluded. This means, in principle, that I am assuming the / experience comes once in over forty years rather than once in fifteen years. You might think this is excessively optimistic, but the point I want to make is that, even with this treatment, the effects of the experience on the shape of the distribution are pronounced. This is, however, not the only way of addressing the issue. In particular, the Committee has always said that it has views only on the central ninety per cent of the distribution of errors. That means that the shape of the distribution should not be distorted by observations lying further out. The methods developed by Kapetanios, Mitchell, Price and Fawcett () may make it possible to fit the distribution only to the central ninety per cent, and I expect that the Committee would wish to pursue that should it want to explore further the issues I am discussing here. The results I present are certainly sensitive to the handling of this issue. In Chart  I show a representation of the GDP forecast error probabilities after down weighting the outliers in the way that I have described, and fitting the resulting series to the two-part t distribution. The shaded green areas show ranges, with each shade describing a range of values which has a ten per cent probability. The darkest green shows the ten per cent band closest to the most likely outcome, or mode, and lighter bands show ten per cent bands which are further from the mode. This chart is therefore an analogue of Chart . published in yesterday s inflation report. But instead of representing the MPC s subjective judgement I am showing a pattern which uses the two-part t distribution to fit our past forecast errors. It is therefore the distribution for our growth forecast at two years which would be appropriate if we thought our future forecasting performance was going to be like our past forecasting performance. You can see that there is a strong skew to the left. The experience of the recession means that, even after the down weighting I have described, large shortfalls relative to our forecasts are more likely than very high growth figures. It is also the case that the appropriate t-distribution has only . degrees of freedom. Despite this being a  fat tails  distribution, the consequence is that the central bands are much tighter together than they are if I represent the same error pattern using the MPC s existing two-part normal distribution. Thus, although the width of the distribution as a whole, which covers ninety per cent of possible outcomes, is marginally wider than that used by the MPC, the central bands are much closer together. Of course, the MPC s judgement is subjective, so there is no reason why it need match this chart, but I think there is a case for using central bands narrower than those shown in the Inflation Report. Chart  and Chart  show the analogous results for the inflation forecast errors. You can see that here the skew is to the upside. It is noteworthy that this is despite the experience of the last two years, when the sharp fall in the oil price and reductions in food prices took the inflation rate close to zero. There is, of course, a case for downplaying some of the large upside errors which accrued from -, but I think it is less good than for reducing the impact of the recession on the growth distribution. Anyway, I have not made any adjustment here. The fitted t-distribution has . degrees of freedom, once again implying a picture rather different from the two-part normal distribution. In this case, the width of the fan is similar for both distributions, but the fitted-distribution has markedly more mass located around the mode. The conclusion that I draw from this exercise is that, although some have been wide of the mark, many of our growth and inflation forecasts are better than we think they are going to be. Looking at the two charts together, the combination of a downside skew to GDP and an upside skew to inflation might be taken to mean that adverse supply shocks, which depress output and push up on inflation, are more likely than adverse demand shocks, which would pull down on both output and inflation. I am not sure that that is the case. It seems to me that the upward skew of the inflation chart, and in particular the way in which the inflation rate barely dropped below zero during the recession, may instead indicate that there is considerable downward stickiness in prices. That could provide a source of skew in the forecast errors at a time of low inflation. Finally, it is worth making a comparison between what emerges from this and the error distribution assumed by the MPC in its May Inflation Report. Chart  and Chart  repeat the fitted two-part t-distributions with the distributions from the latest Inflation Report superimposed. Once again, the modes are located at zero to facilitate the comparison. At least as compared to historic forecasting errors, the MPC s distributions seem to have too much probability mass in the tails. For GDP that seems to be in the upper tail while for inflation it is in the lower tail. This may be desirable because, after all, the Inflation Report fan charts are subjective. The comparison between the historic record and what I have just agreed to for the May Inflation Report does, nevertheless, raise some questions. A critique of all of this is, of course, that this historic experience represents a combination of two very different periods, before and after the crisis. One might therefore judge that the experience after the crisis is a better guide to present uncertainty than is the whole of the MPC s record. Equally, it took some time for at least one member of the MPC (me) to realise how things had changed, and that learning process aggravated our forecasting record. Anyway these are issues which others may have to grapple with. ###newline###  So far I have tried to describe both how we form a picture of what is going on and how we convey the uncertainty surrounding our views of what will go on. But none of you can have avoided noticing that what is going on at the moment is a referendum campaign; we are being asked, for a second time in the voting lives of at least a large minority of us, to vote on the UK s membership of the European Union. Given that the outcome of the vote is going to have important implications for Britain s economic and political future, and since the result is uncertain, you would not be surprised to learn that the Monetary Policy Committee has seen the referendum as a source of uncertainty, with the prospect of this remaining elevated should the nation vote to leave the European Union (Monetary Policy Committee, ). There are any number of reasons why uncertainty should affect economic activity. Keynes () introduced the concept of precautionary saving   people saving up not for some future need, like buying a new car or retirement, but because of what might happen   while Dixit and Pindyck () have drawn attention to the way in which it is likely to affect investment. In fact the impact of aggregate uncertainty on household consumption is likely to be rather small. The reason for this is that, for most people, uncertainty about future spending power arises mainly for idiosyncratic reasons, such as changes in family circumstances, rather than changes in the aggregate state of the economy. Since it is the variance, the square of the standard deviation, rather than the standard deviation itself which is likely to affect the growth in consumption (Deaton, ), even a doubling of aggregate uncertainty will not have much effect on overall uncertainty. The one change which can have a material impact is an increase in unemployment, but even here, I found a few years ago, using a structural model, that a two-point increase in unemployment would still have only a relatively small and short-lived impact on saving (Weale, ). In contrast, the impact of uncertainty on investment is likely to be material (Bloom, ). Consistent with that, investment is a much more volatile component of demand than is household consumption. Denis and Kannan () explore the effects of uncertainty on the economy of the United Kingdom. They use two measures, the volatility of share prices as implied by the market for options on the FTSE  share index and the dispersion of forecasts for GDP growth one year ahead. They suggest that shocks to uncertainty have their maximum effect on GDP at nine months followed by a recovery which takes about two years; not surprisingly, the impact on industrial production is quicker and more pronounced. Work at the Bank on measuring uncertainty has focused on six indicators, the volatility of the FTSE index, the implied volatility of the exchange rate index deduced from options markets, the dispersion of economic forecasts, a count of media references to uncertainty in an economic context and the balances of household views on unemployment and their financial situation as measured by the GfK monthly survey. None of these is ideal, but the hope is that, by taking their principal component, a reasonable overall picture can be obtained. Chart  shows the swathe of these measures together with the principal component. You can see that, although this measure suggests uncertainty has recently picked up to some extent, the level is still appreciably lower than it was between late  and , and not very different from the experience of the Far Eastern crisis of  and the build up to the war in Iraq. I share the collective view of the MPC that the EU referendum is the biggest source of uncertainty at the moment, and this is the main reason why we expect Q growth to be weak. There is reasonably clear evidence that the uncertainty has had a material influence on the exchange rate; over the last few months exchange rate movements have tended to occur when news stories about the referendum were dominant. This is the basis for the Committee s assumption that half of the nine per cent fall in the exchange rate since November is associated with uncertainty surrounding the outcome of the referendum. Consistent with a forecast produced on the assumption that government policy is followed, we assume that this component of the fall does not affect the projections for output and inflation. As in so many areas, the MPC has to produce the best estimates that it can on the basis of the evidence as it is and I am entirely happy with projection that we have just published. Nevertheless, were we to have over-estimated the degree to which the referendum has weighed on sterling, this would raise the prospect of inflation rising noticeably above target in two years or so. This could generate a trade-off between limiting an overshoot to inflation and supporting economic growth. For me that would feel like history repeating itself. ###newline###  The last six years have taught me the importance of making the best of what we have. The evidence available to the Monetary Policy Committee is never as good as we would like it to be and we cannot, of course, delay our judgements to wait for statistically solid findings to emerge. Judgements have to be made on the basis of the balance of probabilities rather than firm levels of statistical significance. These points are material for our regular cycle of estimating what is going on ahead of the first official data, interpreting early estimates and explaining what we can and cannot say about the future. What I have shown you here suggests it may be worth taking another look at the way we represent the uncertainty in our forecast. ###newline###  The regression coefficient below  on the initial estimate in an equation explaining the final estimate can be understood in the following way. Suppose that the economy consists of two sectors, a and b. Sector a has a weight of w and sector b a weight of -w. The output growth of sector a measured relative to mean output growth is, with time subscripts suppressed, Thus the output of each sector consists of a common component and an idiosyncratic component. These cannot be distinguished in the data for any individual quarter, but the idiosyncratic components of the two sectors are uncorrelated. However, only sector a is observed initially, with the data for sector b coming in later. The initial estimate is therefore If the final estimate is regressed on the initial estimate, the regression coefficient is   =     , which tends to  if there is no idiosyncratic component in sector a. It does not matter if there is still an idiosyncratic component in sector b. Suppose that the initial estimates come from % of the economy, so that w=.. Then if the ratio the resulting regression coefficient will be . ./.=.. Thus a substantial but not overwhelming value for   will be enough to deliver the sort of coefficient observed in practice. ###newline###  The two-piece t- distribution has the following density function. Here G() indicates a gamma-function,   is the mode of the two-part distribution and, when there is no skew, it is also the mean and the median,   is a measure of dispersion which, in the absence of skew is also the standard deviation,   is the number of degrees of freedom and   determines the skew. H() is the Heaviside function which takes a value  when its argument is zero or positive and  when its argument is negative. The density function becomes symmetric when   is set to . A value greater than this generates a skew to the right while a value below this generates a skew to the left. The t- distribution converges to the normal distribution as   tends to infinity. In practice a normal distribution can be generated by setting   to some reasonably large number like two hundred. Thus restricting   and restricting   allow us to explore the special cases of symmetry and normality (with or without symmetry). The density function is fitted to a sequence of observations {xi} by maximum likelihood. That is, values of the parameters,   and   are chosen to maximise the sum of the logarithms of the probabilities of each observation conditional on the parameter set.